{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Iajx735-L7O"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('/content/Data_subset1.csv')"
      ],
      "metadata": {
        "id": "a5xUFQFY-kw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "OeXrg_tq-rKG",
        "outputId": "e54bbe54-0772-4570-a246-47c37c7371da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID        b1        b2        b3        b4        b5        b6  \\\n",
              "0      1  0.081264  0.081630  0.080447  0.084221  0.085154  0.088562   \n",
              "1      2  0.081264  0.081630  0.080447  0.084221  0.085154  0.088562   \n",
              "2      3  0.081264  0.081630  0.080447  0.084221  0.085154  0.088562   \n",
              "3      4  0.081264  0.081630  0.080447  0.084221  0.085154  0.088562   \n",
              "4      5  0.081264  0.081630  0.080447  0.084221  0.085154  0.088562   \n",
              "..   ...       ...       ...       ...       ...       ...       ...   \n",
              "811  812  0.078206  0.079817  0.077016  0.080315  0.082159  0.085170   \n",
              "812  813  0.078206  0.079817  0.077016  0.080315  0.082159  0.085170   \n",
              "813  814  0.076448  0.077887  0.076394  0.080611  0.081132  0.084687   \n",
              "814  815  0.078206  0.079817  0.077016  0.080315  0.082159  0.085170   \n",
              "815  816  0.078206  0.079817  0.077016  0.080315  0.082159  0.085170   \n",
              "\n",
              "           b7        b8        b9  ...      b183      b184      b185  \\\n",
              "0    0.084579  0.090803  0.094506  ...  0.021204  0.020077  0.022498   \n",
              "1    0.084579  0.090803  0.094506  ...  0.021204  0.020077  0.022498   \n",
              "2    0.084579  0.090803  0.094506  ...  0.021204  0.020077  0.022498   \n",
              "3    0.084579  0.090803  0.094506  ...  0.021204  0.020077  0.022498   \n",
              "4    0.084579  0.090803  0.094506  ...  0.021204  0.020077  0.022498   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "811  0.083653  0.088803  0.091550  ...  0.020793  0.023350  0.024111   \n",
              "812  0.083653  0.088803  0.091550  ...  0.020793  0.023350  0.024111   \n",
              "813  0.084073  0.087379  0.089745  ...  0.026607  0.020016  0.020808   \n",
              "814  0.083653  0.088803  0.091550  ...  0.020793  0.023350  0.024111   \n",
              "815  0.083653  0.088803  0.091550  ...  0.020793  0.023350  0.024111   \n",
              "\n",
              "         b186      b187      b188      b189      b190      b191  Turbidity  \n",
              "0    0.019879  0.012558  0.016607  0.019179  0.014887  0.016105      17.32  \n",
              "1    0.019879  0.012558  0.016607  0.019179  0.014887  0.016105      20.48  \n",
              "2    0.019879  0.012558  0.016607  0.019179  0.014887  0.016105      17.19  \n",
              "3    0.019879  0.012558  0.016607  0.019179  0.014887  0.016105      17.54  \n",
              "4    0.019879  0.012558  0.016607  0.019179  0.014887  0.016105      19.42  \n",
              "..        ...       ...       ...       ...       ...       ...        ...  \n",
              "811  0.017627  0.016759  0.018555  0.013365  0.019103  0.016531      31.06  \n",
              "812  0.017627  0.016759  0.018555  0.013365  0.019103  0.016531      52.08  \n",
              "813  0.018099  0.016866  0.012725  0.012649  0.026592  0.014826     641.01  \n",
              "814  0.017627  0.016759  0.018555  0.013365  0.019103  0.016531     304.22  \n",
              "815  0.017627  0.016759  0.018555  0.013365  0.019103  0.016531      54.75  \n",
              "\n",
              "[816 rows x 193 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64f6f799-c7eb-445a-8e84-70ca40a1b914\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>b1</th>\n",
              "      <th>b2</th>\n",
              "      <th>b3</th>\n",
              "      <th>b4</th>\n",
              "      <th>b5</th>\n",
              "      <th>b6</th>\n",
              "      <th>b7</th>\n",
              "      <th>b8</th>\n",
              "      <th>b9</th>\n",
              "      <th>...</th>\n",
              "      <th>b183</th>\n",
              "      <th>b184</th>\n",
              "      <th>b185</th>\n",
              "      <th>b186</th>\n",
              "      <th>b187</th>\n",
              "      <th>b188</th>\n",
              "      <th>b189</th>\n",
              "      <th>b190</th>\n",
              "      <th>b191</th>\n",
              "      <th>Turbidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.081264</td>\n",
              "      <td>0.081630</td>\n",
              "      <td>0.080447</td>\n",
              "      <td>0.084221</td>\n",
              "      <td>0.085154</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.084579</td>\n",
              "      <td>0.090803</td>\n",
              "      <td>0.094506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.019879</td>\n",
              "      <td>0.012558</td>\n",
              "      <td>0.016607</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>17.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.081264</td>\n",
              "      <td>0.081630</td>\n",
              "      <td>0.080447</td>\n",
              "      <td>0.084221</td>\n",
              "      <td>0.085154</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.084579</td>\n",
              "      <td>0.090803</td>\n",
              "      <td>0.094506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.019879</td>\n",
              "      <td>0.012558</td>\n",
              "      <td>0.016607</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>20.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.081264</td>\n",
              "      <td>0.081630</td>\n",
              "      <td>0.080447</td>\n",
              "      <td>0.084221</td>\n",
              "      <td>0.085154</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.084579</td>\n",
              "      <td>0.090803</td>\n",
              "      <td>0.094506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.019879</td>\n",
              "      <td>0.012558</td>\n",
              "      <td>0.016607</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>17.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.081264</td>\n",
              "      <td>0.081630</td>\n",
              "      <td>0.080447</td>\n",
              "      <td>0.084221</td>\n",
              "      <td>0.085154</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.084579</td>\n",
              "      <td>0.090803</td>\n",
              "      <td>0.094506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.019879</td>\n",
              "      <td>0.012558</td>\n",
              "      <td>0.016607</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>17.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.081264</td>\n",
              "      <td>0.081630</td>\n",
              "      <td>0.080447</td>\n",
              "      <td>0.084221</td>\n",
              "      <td>0.085154</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.084579</td>\n",
              "      <td>0.090803</td>\n",
              "      <td>0.094506</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.020077</td>\n",
              "      <td>0.022498</td>\n",
              "      <td>0.019879</td>\n",
              "      <td>0.012558</td>\n",
              "      <td>0.016607</td>\n",
              "      <td>0.019179</td>\n",
              "      <td>0.014887</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>19.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>812</td>\n",
              "      <td>0.078206</td>\n",
              "      <td>0.079817</td>\n",
              "      <td>0.077016</td>\n",
              "      <td>0.080315</td>\n",
              "      <td>0.082159</td>\n",
              "      <td>0.085170</td>\n",
              "      <td>0.083653</td>\n",
              "      <td>0.088803</td>\n",
              "      <td>0.091550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020793</td>\n",
              "      <td>0.023350</td>\n",
              "      <td>0.024111</td>\n",
              "      <td>0.017627</td>\n",
              "      <td>0.016759</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>0.013365</td>\n",
              "      <td>0.019103</td>\n",
              "      <td>0.016531</td>\n",
              "      <td>31.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>813</td>\n",
              "      <td>0.078206</td>\n",
              "      <td>0.079817</td>\n",
              "      <td>0.077016</td>\n",
              "      <td>0.080315</td>\n",
              "      <td>0.082159</td>\n",
              "      <td>0.085170</td>\n",
              "      <td>0.083653</td>\n",
              "      <td>0.088803</td>\n",
              "      <td>0.091550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020793</td>\n",
              "      <td>0.023350</td>\n",
              "      <td>0.024111</td>\n",
              "      <td>0.017627</td>\n",
              "      <td>0.016759</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>0.013365</td>\n",
              "      <td>0.019103</td>\n",
              "      <td>0.016531</td>\n",
              "      <td>52.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>814</td>\n",
              "      <td>0.076448</td>\n",
              "      <td>0.077887</td>\n",
              "      <td>0.076394</td>\n",
              "      <td>0.080611</td>\n",
              "      <td>0.081132</td>\n",
              "      <td>0.084687</td>\n",
              "      <td>0.084073</td>\n",
              "      <td>0.087379</td>\n",
              "      <td>0.089745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026607</td>\n",
              "      <td>0.020016</td>\n",
              "      <td>0.020808</td>\n",
              "      <td>0.018099</td>\n",
              "      <td>0.016866</td>\n",
              "      <td>0.012725</td>\n",
              "      <td>0.012649</td>\n",
              "      <td>0.026592</td>\n",
              "      <td>0.014826</td>\n",
              "      <td>641.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>815</td>\n",
              "      <td>0.078206</td>\n",
              "      <td>0.079817</td>\n",
              "      <td>0.077016</td>\n",
              "      <td>0.080315</td>\n",
              "      <td>0.082159</td>\n",
              "      <td>0.085170</td>\n",
              "      <td>0.083653</td>\n",
              "      <td>0.088803</td>\n",
              "      <td>0.091550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020793</td>\n",
              "      <td>0.023350</td>\n",
              "      <td>0.024111</td>\n",
              "      <td>0.017627</td>\n",
              "      <td>0.016759</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>0.013365</td>\n",
              "      <td>0.019103</td>\n",
              "      <td>0.016531</td>\n",
              "      <td>304.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>816</td>\n",
              "      <td>0.078206</td>\n",
              "      <td>0.079817</td>\n",
              "      <td>0.077016</td>\n",
              "      <td>0.080315</td>\n",
              "      <td>0.082159</td>\n",
              "      <td>0.085170</td>\n",
              "      <td>0.083653</td>\n",
              "      <td>0.088803</td>\n",
              "      <td>0.091550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020793</td>\n",
              "      <td>0.023350</td>\n",
              "      <td>0.024111</td>\n",
              "      <td>0.017627</td>\n",
              "      <td>0.016759</td>\n",
              "      <td>0.018555</td>\n",
              "      <td>0.013365</td>\n",
              "      <td>0.019103</td>\n",
              "      <td>0.016531</td>\n",
              "      <td>54.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>816 rows × 193 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64f6f799-c7eb-445a-8e84-70ca40a1b914')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64f6f799-c7eb-445a-8e84-70ca40a1b914 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64f6f799-c7eb-445a-8e84-70ca40a1b914');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target (y)\n",
        "X = data.iloc[:, 1:192].values\n",
        "y = data.iloc[:, 192].values"
      ],
      "metadata": {
        "id": "w6Hlh5Mu-vIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "nvo-VaJqBhXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of regressors to use\n",
        "regressors = [RandomForestRegressor(n_estimators=100, random_state=0),\n",
        "              DecisionTreeRegressor(random_state=0),\n",
        "              LinearRegression(),\n",
        "              Ridge(),\n",
        "              Lasso(),\n",
        "              SVR(),\n",
        "              KNeighborsRegressor(),\n",
        "              XGBRegressor(random_state=0),\n",
        "              LGBMRegressor(random_state=0)]"
      ],
      "metadata": {
        "id": "oelCX7_HBoLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each regressor\n",
        "for regressor in regressors:\n",
        "    # Train the regressor\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the target values\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    # Calculate the mean squared error and R-squared score\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the results\n",
        "    print(regressor.__class__.__name__)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAPE:', mape)\n",
        "    print('R-squared:', r2)\n",
        "    #print('Feature Importances:', regressor.feature_importances_ if hasattr(regressor, 'feature_importances_') else 'N/A')\n",
        "    print('-' * 50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHCS6_y6BsCW",
        "outputId": "d19b07ce-5452-4a0b-8bcf-4f05532da880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor\n",
            "MSE: 1423.7220577077308\n",
            "RMSE: 37.73224162049918\n",
            "MAPE: 28.173983034533144\n",
            "R-squared: -1.3523145061080313\n",
            "--------------------------------------------------\n",
            "DecisionTreeRegressor\n",
            "MSE: 3538.463753601695\n",
            "RMSE: 59.48498763218914\n",
            "MAPE: 25.542906682390747\n",
            "R-squared: -4.846351520560238\n",
            "--------------------------------------------------\n",
            "LinearRegression\n",
            "MSE: 315.01844966342054\n",
            "RMSE: 17.748759102073038\n",
            "MAPE: 50.479693400641125\n",
            "R-squared: 0.479517462819946\n",
            "--------------------------------------------------\n",
            "Ridge\n",
            "MSE: 584.6792748586037\n",
            "RMSE: 24.18014215960286\n",
            "MAPE: 37.027788137972465\n",
            "R-squared: 0.03397609651071576\n",
            "--------------------------------------------------\n",
            "Lasso\n",
            "MSE: 611.5492691586634\n",
            "RMSE: 24.729522218568302\n",
            "MAPE: 35.9729377145991\n",
            "R-squared: -0.01041928040213258\n",
            "--------------------------------------------------\n",
            "SVR\n",
            "MSE: 622.7662712418982\n",
            "RMSE: 24.95528543699507\n",
            "MAPE: 9.969652291886355\n",
            "R-squared: -0.02895233365686667\n",
            "--------------------------------------------------\n",
            "KNeighborsRegressor\n",
            "MSE: 671.964513694915\n",
            "RMSE: 25.922278327626124\n",
            "MAPE: 17.610908505608833\n",
            "R-squared: -0.11023908395388937\n",
            "--------------------------------------------------\n",
            "MLPRegressor\n",
            "MSE: 609.6914413317824\n",
            "RMSE: 24.691930692673314\n",
            "MAPE: 36.91080004041811\n",
            "R-squared: -0.0073497238665967135\n",
            "--------------------------------------------------\n",
            "XGBRegressor\n",
            "MSE: 4244.198837171947\n",
            "RMSE: 65.1475159708484\n",
            "MAPE: 36.42940245571531\n",
            "R-squared: -6.012387310737245\n",
            "--------------------------------------------------\n",
            "LGBMRegressor\n",
            "MSE: 571.5331245948352\n",
            "RMSE: 23.906758973035956\n",
            "MAPE: 32.09635763672785\n",
            "R-squared: 0.05569654383926781\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('regressor_scores.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Regressor', 'MSE', 'RMSE', 'MAPE', 'R-squared'])\n",
        "    for regressor in regressors:\n",
        "        regressor.fit(X_train, y_train)\n",
        "        y_pred = regressor.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        writer.writerow([regressor.__class__.__name__, mse, rmse, mape, r2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VS7LWRFQQxp",
        "outputId": "95ffde76-a846-485e-cbc5-5ad67103d48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "id": "5G32nLcmSYAJ",
        "outputId": "ccef163e-a35d-43e4-a44d-566e4d943f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.2.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ],
      "metadata": {
        "id": "prvah1onRu75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "3c37ef40-03ba-4333-a52b-0050d519aacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8cbb48d074a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Data_subset1.csv')"
      ],
      "metadata": {
        "id": "7oTnzF_uSdUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:192].values\n",
        "y = df.iloc[:, 192].values"
      ],
      "metadata": {
        "id": "_-SQpCQrI9F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YNP-MPE-JJDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the 10 machine learning algorithms\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "lr = LinearRegression()\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "svm = SVR(kernel='linear')\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "lgbm = LGBMRegressor(random_state=42)\n",
        "cat = CatBoostRegressor(random_state=42)\n",
        "mlp = MLPRegressor(random_state=42)\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "et = ExtraTreesRegressor(random_state=42)\n"
      ],
      "metadata": {
        "id": "IpJxrwnbJZCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit each algorithm on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)\n",
        "lgbm.fit(X_train, y_train)\n",
        "cat.fit(X_train, y_train)\n",
        "mlp.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "et.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTnMag6hJcXE",
        "outputId": "8ab73200-7dec-4ab2-89f6-27b8397ebffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.038041\n",
            "0:\tlearn: 46.2867409\ttotal: 77.7ms\tremaining: 1m 17s\n",
            "1:\tlearn: 45.8676621\ttotal: 121ms\tremaining: 1m\n",
            "2:\tlearn: 45.4465150\ttotal: 165ms\tremaining: 54.7s\n",
            "3:\tlearn: 45.1233560\ttotal: 215ms\tremaining: 53.6s\n",
            "4:\tlearn: 44.6415861\ttotal: 261ms\tremaining: 51.9s\n",
            "5:\tlearn: 44.2493014\ttotal: 304ms\tremaining: 50.4s\n",
            "6:\tlearn: 43.8604404\ttotal: 349ms\tremaining: 49.5s\n",
            "7:\tlearn: 43.4709588\ttotal: 397ms\tremaining: 49.2s\n",
            "8:\tlearn: 43.2879785\ttotal: 449ms\tremaining: 49.5s\n",
            "9:\tlearn: 42.9100197\ttotal: 496ms\tremaining: 49.1s\n",
            "10:\tlearn: 42.5442919\ttotal: 545ms\tremaining: 49s\n",
            "11:\tlearn: 42.0976163\ttotal: 602ms\tremaining: 49.6s\n",
            "12:\tlearn: 41.7342188\ttotal: 649ms\tremaining: 49.3s\n",
            "13:\tlearn: 41.4176533\ttotal: 705ms\tremaining: 49.6s\n",
            "14:\tlearn: 41.0768463\ttotal: 753ms\tremaining: 49.4s\n",
            "15:\tlearn: 40.7289139\ttotal: 800ms\tremaining: 49.2s\n",
            "16:\tlearn: 40.3383005\ttotal: 865ms\tremaining: 50s\n",
            "17:\tlearn: 39.9650022\ttotal: 914ms\tremaining: 49.9s\n",
            "18:\tlearn: 39.6596539\ttotal: 968ms\tremaining: 50s\n",
            "19:\tlearn: 39.3750656\ttotal: 1.02s\tremaining: 50s\n",
            "20:\tlearn: 39.1226818\ttotal: 1.08s\tremaining: 50.6s\n",
            "21:\tlearn: 38.8472418\ttotal: 1.13s\tremaining: 50.4s\n",
            "22:\tlearn: 38.5439752\ttotal: 1.18s\tremaining: 50.1s\n",
            "23:\tlearn: 38.2388915\ttotal: 1.23s\tremaining: 49.9s\n",
            "24:\tlearn: 37.9501454\ttotal: 1.27s\tremaining: 49.7s\n",
            "25:\tlearn: 37.6935792\ttotal: 1.33s\tremaining: 49.9s\n",
            "26:\tlearn: 37.4502744\ttotal: 1.38s\tremaining: 49.8s\n",
            "27:\tlearn: 37.2185588\ttotal: 1.44s\tremaining: 50s\n",
            "28:\tlearn: 36.9832236\ttotal: 1.53s\tremaining: 51.2s\n",
            "29:\tlearn: 36.7219000\ttotal: 1.63s\tremaining: 52.6s\n",
            "30:\tlearn: 36.4905983\ttotal: 1.73s\tremaining: 53.9s\n",
            "31:\tlearn: 36.2503431\ttotal: 1.82s\tremaining: 55.1s\n",
            "32:\tlearn: 36.0196547\ttotal: 1.93s\tremaining: 56.4s\n",
            "33:\tlearn: 35.7879329\ttotal: 2.02s\tremaining: 57.4s\n",
            "34:\tlearn: 35.5607254\ttotal: 2.12s\tremaining: 58.4s\n",
            "35:\tlearn: 35.3275557\ttotal: 2.21s\tremaining: 59.2s\n",
            "36:\tlearn: 35.1272761\ttotal: 2.31s\tremaining: 1m\n",
            "37:\tlearn: 34.9234054\ttotal: 2.39s\tremaining: 1m\n",
            "38:\tlearn: 34.7401395\ttotal: 2.48s\tremaining: 1m 1s\n",
            "39:\tlearn: 34.5038550\ttotal: 2.57s\tremaining: 1m 1s\n",
            "40:\tlearn: 34.3055498\ttotal: 2.67s\tremaining: 1m 2s\n",
            "41:\tlearn: 34.1255472\ttotal: 2.77s\tremaining: 1m 3s\n",
            "42:\tlearn: 33.9281096\ttotal: 2.87s\tremaining: 1m 3s\n",
            "43:\tlearn: 33.7512672\ttotal: 2.97s\tremaining: 1m 4s\n",
            "44:\tlearn: 33.6246390\ttotal: 3.06s\tremaining: 1m 5s\n",
            "45:\tlearn: 33.4522241\ttotal: 3.16s\tremaining: 1m 5s\n",
            "46:\tlearn: 33.2457777\ttotal: 3.25s\tremaining: 1m 5s\n",
            "47:\tlearn: 33.0868969\ttotal: 3.33s\tremaining: 1m 6s\n",
            "48:\tlearn: 32.9017293\ttotal: 3.42s\tremaining: 1m 6s\n",
            "49:\tlearn: 32.7511446\ttotal: 3.5s\tremaining: 1m 6s\n",
            "50:\tlearn: 32.6053975\ttotal: 3.59s\tremaining: 1m 6s\n",
            "51:\tlearn: 32.4620823\ttotal: 3.69s\tremaining: 1m 7s\n",
            "52:\tlearn: 32.2864457\ttotal: 3.79s\tremaining: 1m 7s\n",
            "53:\tlearn: 32.0622838\ttotal: 3.88s\tremaining: 1m 8s\n",
            "54:\tlearn: 31.9275785\ttotal: 3.97s\tremaining: 1m 8s\n",
            "55:\tlearn: 31.7765862\ttotal: 4.06s\tremaining: 1m 8s\n",
            "56:\tlearn: 31.6349431\ttotal: 4.14s\tremaining: 1m 8s\n",
            "57:\tlearn: 31.4615639\ttotal: 4.22s\tremaining: 1m 8s\n",
            "58:\tlearn: 31.2650436\ttotal: 4.32s\tremaining: 1m 8s\n",
            "59:\tlearn: 31.1103691\ttotal: 4.4s\tremaining: 1m 8s\n",
            "60:\tlearn: 30.9117119\ttotal: 4.44s\tremaining: 1m 8s\n",
            "61:\tlearn: 30.7971013\ttotal: 4.49s\tremaining: 1m 7s\n",
            "62:\tlearn: 30.6455483\ttotal: 4.53s\tremaining: 1m 7s\n",
            "63:\tlearn: 30.5552257\ttotal: 4.58s\tremaining: 1m 7s\n",
            "64:\tlearn: 30.4321200\ttotal: 4.63s\tremaining: 1m 6s\n",
            "65:\tlearn: 30.3142414\ttotal: 4.67s\tremaining: 1m 6s\n",
            "66:\tlearn: 30.1754733\ttotal: 4.71s\tremaining: 1m 5s\n",
            "67:\tlearn: 30.0619956\ttotal: 4.77s\tremaining: 1m 5s\n",
            "68:\tlearn: 29.9337955\ttotal: 4.81s\tremaining: 1m 4s\n",
            "69:\tlearn: 29.7943388\ttotal: 4.86s\tremaining: 1m 4s\n",
            "70:\tlearn: 29.6886082\ttotal: 4.91s\tremaining: 1m 4s\n",
            "71:\tlearn: 29.5926829\ttotal: 4.96s\tremaining: 1m 3s\n",
            "72:\tlearn: 29.4829702\ttotal: 5.02s\tremaining: 1m 3s\n",
            "73:\tlearn: 29.3859568\ttotal: 5.06s\tremaining: 1m 3s\n",
            "74:\tlearn: 29.2619119\ttotal: 5.11s\tremaining: 1m 2s\n",
            "75:\tlearn: 29.1711824\ttotal: 5.15s\tremaining: 1m 2s\n",
            "76:\tlearn: 29.0308690\ttotal: 5.19s\tremaining: 1m 2s\n",
            "77:\tlearn: 28.9231278\ttotal: 5.24s\tremaining: 1m 1s\n",
            "78:\tlearn: 28.8345911\ttotal: 5.29s\tremaining: 1m 1s\n",
            "79:\tlearn: 28.7437270\ttotal: 5.34s\tremaining: 1m 1s\n",
            "80:\tlearn: 28.6272169\ttotal: 5.39s\tremaining: 1m 1s\n",
            "81:\tlearn: 28.5482790\ttotal: 5.44s\tremaining: 1m\n",
            "82:\tlearn: 28.4661445\ttotal: 5.49s\tremaining: 1m\n",
            "83:\tlearn: 28.3785186\ttotal: 5.53s\tremaining: 1m\n",
            "84:\tlearn: 28.2943654\ttotal: 5.58s\tremaining: 1m\n",
            "85:\tlearn: 28.1939651\ttotal: 5.62s\tremaining: 59.8s\n",
            "86:\tlearn: 28.1281171\ttotal: 5.67s\tremaining: 59.5s\n",
            "87:\tlearn: 28.0328607\ttotal: 5.72s\tremaining: 59.3s\n",
            "88:\tlearn: 27.9381136\ttotal: 5.76s\tremaining: 59s\n",
            "89:\tlearn: 27.8360496\ttotal: 5.81s\tremaining: 58.7s\n",
            "90:\tlearn: 27.7618833\ttotal: 5.85s\tremaining: 58.5s\n",
            "91:\tlearn: 27.7269375\ttotal: 5.9s\tremaining: 58.2s\n",
            "92:\tlearn: 27.6304651\ttotal: 5.95s\tremaining: 58s\n",
            "93:\tlearn: 27.5504048\ttotal: 6s\tremaining: 57.8s\n",
            "94:\tlearn: 27.5246171\ttotal: 6.04s\tremaining: 57.6s\n",
            "95:\tlearn: 27.4491960\ttotal: 6.09s\tremaining: 57.3s\n",
            "96:\tlearn: 27.3826173\ttotal: 6.13s\tremaining: 57.1s\n",
            "97:\tlearn: 27.3283543\ttotal: 6.18s\tremaining: 56.9s\n",
            "98:\tlearn: 27.2565891\ttotal: 6.23s\tremaining: 56.7s\n",
            "99:\tlearn: 27.2162722\ttotal: 6.27s\tremaining: 56.5s\n",
            "100:\tlearn: 27.1549425\ttotal: 6.33s\tremaining: 56.3s\n",
            "101:\tlearn: 27.0869423\ttotal: 6.37s\tremaining: 56.1s\n",
            "102:\tlearn: 27.0193133\ttotal: 6.42s\tremaining: 55.9s\n",
            "103:\tlearn: 26.9521954\ttotal: 6.46s\tremaining: 55.7s\n",
            "104:\tlearn: 26.8931644\ttotal: 6.51s\tremaining: 55.5s\n",
            "105:\tlearn: 26.8542749\ttotal: 6.55s\tremaining: 55.3s\n",
            "106:\tlearn: 26.8003549\ttotal: 6.6s\tremaining: 55.1s\n",
            "107:\tlearn: 26.7332778\ttotal: 6.65s\tremaining: 54.9s\n",
            "108:\tlearn: 26.6732507\ttotal: 6.69s\tremaining: 54.7s\n",
            "109:\tlearn: 26.6165592\ttotal: 6.74s\tremaining: 54.5s\n",
            "110:\tlearn: 26.5576296\ttotal: 6.78s\tremaining: 54.3s\n",
            "111:\tlearn: 26.5069844\ttotal: 6.83s\tremaining: 54.1s\n",
            "112:\tlearn: 26.4561568\ttotal: 6.88s\tremaining: 54s\n",
            "113:\tlearn: 26.3996618\ttotal: 6.92s\tremaining: 53.8s\n",
            "114:\tlearn: 26.3533338\ttotal: 6.97s\tremaining: 53.6s\n",
            "115:\tlearn: 26.3063748\ttotal: 7.03s\tremaining: 53.5s\n",
            "116:\tlearn: 26.2639633\ttotal: 7.07s\tremaining: 53.3s\n",
            "117:\tlearn: 26.2084652\ttotal: 7.12s\tremaining: 53.2s\n",
            "118:\tlearn: 26.1490128\ttotal: 7.16s\tremaining: 53s\n",
            "119:\tlearn: 26.0976388\ttotal: 7.21s\tremaining: 52.9s\n",
            "120:\tlearn: 26.0423256\ttotal: 7.25s\tremaining: 52.7s\n",
            "121:\tlearn: 26.0109213\ttotal: 7.3s\tremaining: 52.5s\n",
            "122:\tlearn: 25.9602590\ttotal: 7.35s\tremaining: 52.4s\n",
            "123:\tlearn: 25.9322877\ttotal: 7.39s\tremaining: 52.2s\n",
            "124:\tlearn: 25.8913021\ttotal: 7.43s\tremaining: 52s\n",
            "125:\tlearn: 25.8443479\ttotal: 7.48s\tremaining: 51.9s\n",
            "126:\tlearn: 25.7989975\ttotal: 7.53s\tremaining: 51.8s\n",
            "127:\tlearn: 25.7650654\ttotal: 7.58s\tremaining: 51.7s\n",
            "128:\tlearn: 25.7134235\ttotal: 7.63s\tremaining: 51.5s\n",
            "129:\tlearn: 25.6972456\ttotal: 7.67s\tremaining: 51.3s\n",
            "130:\tlearn: 25.6610966\ttotal: 7.73s\tremaining: 51.3s\n",
            "131:\tlearn: 25.6289618\ttotal: 7.77s\tremaining: 51.1s\n",
            "132:\tlearn: 25.6031725\ttotal: 7.83s\tremaining: 51s\n",
            "133:\tlearn: 25.5726884\ttotal: 7.87s\tremaining: 50.9s\n",
            "134:\tlearn: 25.5440472\ttotal: 7.91s\tremaining: 50.7s\n",
            "135:\tlearn: 25.5083140\ttotal: 7.96s\tremaining: 50.5s\n",
            "136:\tlearn: 25.4802044\ttotal: 8.01s\tremaining: 50.5s\n",
            "137:\tlearn: 25.4408481\ttotal: 8.06s\tremaining: 50.3s\n",
            "138:\tlearn: 25.4057785\ttotal: 8.1s\tremaining: 50.2s\n",
            "139:\tlearn: 25.3816260\ttotal: 8.15s\tremaining: 50s\n",
            "140:\tlearn: 25.3574777\ttotal: 8.2s\tremaining: 49.9s\n",
            "141:\tlearn: 25.3231851\ttotal: 8.24s\tremaining: 49.8s\n",
            "142:\tlearn: 25.2953997\ttotal: 8.29s\tremaining: 49.7s\n",
            "143:\tlearn: 25.2690925\ttotal: 8.34s\tremaining: 49.5s\n",
            "144:\tlearn: 25.2414195\ttotal: 8.38s\tremaining: 49.4s\n",
            "145:\tlearn: 25.2049850\ttotal: 8.42s\tremaining: 49.3s\n",
            "146:\tlearn: 25.1782356\ttotal: 8.47s\tremaining: 49.1s\n",
            "147:\tlearn: 25.1657084\ttotal: 8.52s\tremaining: 49.1s\n",
            "148:\tlearn: 25.1235765\ttotal: 8.57s\tremaining: 49s\n",
            "149:\tlearn: 25.0871520\ttotal: 8.63s\tremaining: 48.9s\n",
            "150:\tlearn: 25.0610201\ttotal: 8.67s\tremaining: 48.8s\n",
            "151:\tlearn: 25.0326704\ttotal: 8.73s\tremaining: 48.7s\n",
            "152:\tlearn: 25.0090371\ttotal: 8.78s\tremaining: 48.6s\n",
            "153:\tlearn: 24.9789309\ttotal: 8.83s\tremaining: 48.5s\n",
            "154:\tlearn: 24.9537680\ttotal: 8.88s\tremaining: 48.4s\n",
            "155:\tlearn: 24.9343848\ttotal: 8.92s\tremaining: 48.3s\n",
            "156:\tlearn: 24.9167555\ttotal: 8.98s\tremaining: 48.2s\n",
            "157:\tlearn: 24.8933432\ttotal: 9.04s\tremaining: 48.1s\n",
            "158:\tlearn: 24.8715546\ttotal: 9.1s\tremaining: 48.1s\n",
            "159:\tlearn: 24.8530024\ttotal: 9.14s\tremaining: 48s\n",
            "160:\tlearn: 24.8252219\ttotal: 9.2s\tremaining: 47.9s\n",
            "161:\tlearn: 24.7861881\ttotal: 9.25s\tremaining: 47.8s\n",
            "162:\tlearn: 24.7641452\ttotal: 9.29s\tremaining: 47.7s\n",
            "163:\tlearn: 24.7292878\ttotal: 9.34s\tremaining: 47.6s\n",
            "164:\tlearn: 24.6987541\ttotal: 9.4s\tremaining: 47.6s\n",
            "165:\tlearn: 24.6754794\ttotal: 9.45s\tremaining: 47.5s\n",
            "166:\tlearn: 24.6569896\ttotal: 9.5s\tremaining: 47.4s\n",
            "167:\tlearn: 24.6413867\ttotal: 9.54s\tremaining: 47.3s\n",
            "168:\tlearn: 24.6208142\ttotal: 9.6s\tremaining: 47.2s\n",
            "169:\tlearn: 24.6032852\ttotal: 9.64s\tremaining: 47.1s\n",
            "170:\tlearn: 24.5875553\ttotal: 9.69s\tremaining: 47s\n",
            "171:\tlearn: 24.5663856\ttotal: 9.73s\tremaining: 46.8s\n",
            "172:\tlearn: 24.5395949\ttotal: 9.77s\tremaining: 46.7s\n",
            "173:\tlearn: 24.5239638\ttotal: 9.82s\tremaining: 46.6s\n",
            "174:\tlearn: 24.5060833\ttotal: 9.87s\tremaining: 46.5s\n",
            "175:\tlearn: 24.4729763\ttotal: 9.91s\tremaining: 46.4s\n",
            "176:\tlearn: 24.4647070\ttotal: 9.96s\tremaining: 46.3s\n",
            "177:\tlearn: 24.4468379\ttotal: 10s\tremaining: 46.2s\n",
            "178:\tlearn: 24.4285762\ttotal: 10.1s\tremaining: 46.1s\n",
            "179:\tlearn: 24.4187876\ttotal: 10.1s\tremaining: 46s\n",
            "180:\tlearn: 24.3951954\ttotal: 10.2s\tremaining: 46s\n",
            "181:\tlearn: 24.3744157\ttotal: 10.2s\tremaining: 45.9s\n",
            "182:\tlearn: 24.3493218\ttotal: 10.2s\tremaining: 45.8s\n",
            "183:\tlearn: 24.3426466\ttotal: 10.3s\tremaining: 45.6s\n",
            "184:\tlearn: 24.3210607\ttotal: 10.3s\tremaining: 45.5s\n",
            "185:\tlearn: 24.2983695\ttotal: 10.4s\tremaining: 45.5s\n",
            "186:\tlearn: 24.2803418\ttotal: 10.4s\tremaining: 45.4s\n",
            "187:\tlearn: 24.2578229\ttotal: 10.5s\tremaining: 45.3s\n",
            "188:\tlearn: 24.2390268\ttotal: 10.5s\tremaining: 45.2s\n",
            "189:\tlearn: 24.2227234\ttotal: 10.6s\tremaining: 45.1s\n",
            "190:\tlearn: 24.2009282\ttotal: 10.6s\tremaining: 45s\n",
            "191:\tlearn: 24.1773543\ttotal: 10.7s\tremaining: 44.9s\n",
            "192:\tlearn: 24.1583648\ttotal: 10.7s\tremaining: 44.8s\n",
            "193:\tlearn: 24.1391167\ttotal: 10.8s\tremaining: 44.7s\n",
            "194:\tlearn: 24.1267012\ttotal: 10.8s\tremaining: 44.6s\n",
            "195:\tlearn: 24.1047635\ttotal: 10.9s\tremaining: 44.5s\n",
            "196:\tlearn: 24.0880623\ttotal: 10.9s\tremaining: 44.4s\n",
            "197:\tlearn: 24.0708712\ttotal: 10.9s\tremaining: 44.4s\n",
            "198:\tlearn: 24.0528481\ttotal: 11s\tremaining: 44.3s\n",
            "199:\tlearn: 24.0357473\ttotal: 11s\tremaining: 44.2s\n",
            "200:\tlearn: 24.0240781\ttotal: 11.1s\tremaining: 44.1s\n",
            "201:\tlearn: 24.0064315\ttotal: 11.1s\tremaining: 44s\n",
            "202:\tlearn: 24.0002064\ttotal: 11.2s\tremaining: 43.9s\n",
            "203:\tlearn: 23.9860449\ttotal: 11.2s\tremaining: 43.9s\n",
            "204:\tlearn: 23.9689566\ttotal: 11.3s\tremaining: 43.8s\n",
            "205:\tlearn: 23.9514643\ttotal: 11.3s\tremaining: 43.7s\n",
            "206:\tlearn: 23.9410416\ttotal: 11.4s\tremaining: 43.6s\n",
            "207:\tlearn: 23.9310654\ttotal: 11.4s\tremaining: 43.5s\n",
            "208:\tlearn: 23.9144103\ttotal: 11.5s\tremaining: 43.4s\n",
            "209:\tlearn: 23.8979010\ttotal: 11.5s\tremaining: 43.3s\n",
            "210:\tlearn: 23.8826285\ttotal: 11.6s\tremaining: 43.3s\n",
            "211:\tlearn: 23.8736683\ttotal: 11.6s\tremaining: 43.2s\n",
            "212:\tlearn: 23.8561489\ttotal: 11.7s\tremaining: 43.1s\n",
            "213:\tlearn: 23.8417150\ttotal: 11.7s\tremaining: 43s\n",
            "214:\tlearn: 23.8264526\ttotal: 11.8s\tremaining: 43s\n",
            "215:\tlearn: 23.8107809\ttotal: 11.8s\tremaining: 42.9s\n",
            "216:\tlearn: 23.7967154\ttotal: 11.9s\tremaining: 42.8s\n",
            "217:\tlearn: 23.7842063\ttotal: 11.9s\tremaining: 42.8s\n",
            "218:\tlearn: 23.7765275\ttotal: 12s\tremaining: 42.7s\n",
            "219:\tlearn: 23.7632206\ttotal: 12s\tremaining: 42.7s\n",
            "220:\tlearn: 23.7507245\ttotal: 12.1s\tremaining: 42.6s\n",
            "221:\tlearn: 23.7369687\ttotal: 12.2s\tremaining: 42.6s\n",
            "222:\tlearn: 23.7226755\ttotal: 12.2s\tremaining: 42.5s\n",
            "223:\tlearn: 23.7072566\ttotal: 12.3s\tremaining: 42.4s\n",
            "224:\tlearn: 23.7010506\ttotal: 12.3s\tremaining: 42.4s\n",
            "225:\tlearn: 23.6862999\ttotal: 12.4s\tremaining: 42.3s\n",
            "226:\tlearn: 23.6740293\ttotal: 12.4s\tremaining: 42.2s\n",
            "227:\tlearn: 23.6611569\ttotal: 12.4s\tremaining: 42.2s\n",
            "228:\tlearn: 23.6492647\ttotal: 12.5s\tremaining: 42.1s\n",
            "229:\tlearn: 23.6432369\ttotal: 12.6s\tremaining: 42.1s\n",
            "230:\tlearn: 23.6294350\ttotal: 12.6s\tremaining: 42s\n",
            "231:\tlearn: 23.6186170\ttotal: 12.7s\tremaining: 41.9s\n",
            "232:\tlearn: 23.6070366\ttotal: 12.7s\tremaining: 41.8s\n",
            "233:\tlearn: 23.5958824\ttotal: 12.8s\tremaining: 41.8s\n",
            "234:\tlearn: 23.5858945\ttotal: 12.8s\tremaining: 41.7s\n",
            "235:\tlearn: 23.5797464\ttotal: 12.9s\tremaining: 41.6s\n",
            "236:\tlearn: 23.5744147\ttotal: 12.9s\tremaining: 41.6s\n",
            "237:\tlearn: 23.5619149\ttotal: 13s\tremaining: 41.5s\n",
            "238:\tlearn: 23.5512540\ttotal: 13s\tremaining: 41.4s\n",
            "239:\tlearn: 23.5404421\ttotal: 13.1s\tremaining: 41.3s\n",
            "240:\tlearn: 23.5347609\ttotal: 13.1s\tremaining: 41.3s\n",
            "241:\tlearn: 23.5239962\ttotal: 13.2s\tremaining: 41.3s\n",
            "242:\tlearn: 23.5136313\ttotal: 13.2s\tremaining: 41.2s\n",
            "243:\tlearn: 23.5036506\ttotal: 13.3s\tremaining: 41.1s\n",
            "244:\tlearn: 23.4947559\ttotal: 13.3s\tremaining: 41.1s\n",
            "245:\tlearn: 23.4902327\ttotal: 13.4s\tremaining: 41s\n",
            "246:\tlearn: 23.4795301\ttotal: 13.4s\tremaining: 41s\n",
            "247:\tlearn: 23.4709868\ttotal: 13.5s\tremaining: 40.9s\n",
            "248:\tlearn: 23.4618421\ttotal: 13.5s\tremaining: 40.8s\n",
            "249:\tlearn: 23.4520170\ttotal: 13.6s\tremaining: 40.8s\n",
            "250:\tlearn: 23.4448479\ttotal: 13.6s\tremaining: 40.7s\n",
            "251:\tlearn: 23.4355783\ttotal: 13.7s\tremaining: 40.6s\n",
            "252:\tlearn: 23.4240436\ttotal: 13.7s\tremaining: 40.5s\n",
            "253:\tlearn: 23.4151559\ttotal: 13.8s\tremaining: 40.4s\n",
            "254:\tlearn: 23.4064978\ttotal: 13.8s\tremaining: 40.4s\n",
            "255:\tlearn: 23.4016854\ttotal: 13.9s\tremaining: 40.3s\n",
            "256:\tlearn: 23.3929746\ttotal: 13.9s\tremaining: 40.2s\n",
            "257:\tlearn: 23.3847055\ttotal: 14s\tremaining: 40.1s\n",
            "258:\tlearn: 23.3767042\ttotal: 14s\tremaining: 40.1s\n",
            "259:\tlearn: 23.3694378\ttotal: 14.1s\tremaining: 40s\n",
            "260:\tlearn: 23.3610790\ttotal: 14.1s\tremaining: 40s\n",
            "261:\tlearn: 23.3524776\ttotal: 14.2s\tremaining: 39.9s\n",
            "262:\tlearn: 23.3456727\ttotal: 14.2s\tremaining: 39.8s\n",
            "263:\tlearn: 23.3380068\ttotal: 14.3s\tremaining: 39.8s\n",
            "264:\tlearn: 23.3334106\ttotal: 14.3s\tremaining: 39.7s\n",
            "265:\tlearn: 23.3252128\ttotal: 14.4s\tremaining: 39.8s\n",
            "266:\tlearn: 23.3158996\ttotal: 14.5s\tremaining: 39.9s\n",
            "267:\tlearn: 23.3090068\ttotal: 14.6s\tremaining: 39.9s\n",
            "268:\tlearn: 23.3015687\ttotal: 14.7s\tremaining: 39.9s\n",
            "269:\tlearn: 23.2945632\ttotal: 14.8s\tremaining: 40s\n",
            "270:\tlearn: 23.2898913\ttotal: 14.9s\tremaining: 40s\n",
            "271:\tlearn: 23.2856601\ttotal: 15s\tremaining: 40s\n",
            "272:\tlearn: 23.2811195\ttotal: 15.1s\tremaining: 40.1s\n",
            "273:\tlearn: 23.2740563\ttotal: 15.1s\tremaining: 40.1s\n",
            "274:\tlearn: 23.2667515\ttotal: 15.2s\tremaining: 40.1s\n",
            "275:\tlearn: 23.2608096\ttotal: 15.3s\tremaining: 40.1s\n",
            "276:\tlearn: 23.2561130\ttotal: 15.4s\tremaining: 40.1s\n",
            "277:\tlearn: 23.2504546\ttotal: 15.5s\tremaining: 40.2s\n",
            "278:\tlearn: 23.2434987\ttotal: 15.5s\tremaining: 40.1s\n",
            "279:\tlearn: 23.2383308\ttotal: 15.6s\tremaining: 40.2s\n",
            "280:\tlearn: 23.2303765\ttotal: 15.7s\tremaining: 40.2s\n",
            "281:\tlearn: 23.2211662\ttotal: 15.8s\tremaining: 40.3s\n",
            "282:\tlearn: 23.2151326\ttotal: 15.9s\tremaining: 40.3s\n",
            "283:\tlearn: 23.2085577\ttotal: 16s\tremaining: 40.4s\n",
            "284:\tlearn: 23.2046758\ttotal: 16.1s\tremaining: 40.4s\n",
            "285:\tlearn: 23.2001154\ttotal: 16.2s\tremaining: 40.4s\n",
            "286:\tlearn: 23.1965888\ttotal: 16.3s\tremaining: 40.5s\n",
            "287:\tlearn: 23.1915555\ttotal: 16.4s\tremaining: 40.5s\n",
            "288:\tlearn: 23.1871578\ttotal: 16.5s\tremaining: 40.6s\n",
            "289:\tlearn: 23.1810427\ttotal: 16.6s\tremaining: 40.6s\n",
            "290:\tlearn: 23.1746547\ttotal: 16.7s\tremaining: 40.6s\n",
            "291:\tlearn: 23.1686282\ttotal: 16.7s\tremaining: 40.6s\n",
            "292:\tlearn: 23.1620826\ttotal: 16.8s\tremaining: 40.6s\n",
            "293:\tlearn: 23.1555885\ttotal: 16.9s\tremaining: 40.6s\n",
            "294:\tlearn: 23.1513583\ttotal: 17s\tremaining: 40.7s\n",
            "295:\tlearn: 23.1478095\ttotal: 17.1s\tremaining: 40.7s\n",
            "296:\tlearn: 23.1446408\ttotal: 17.2s\tremaining: 40.7s\n",
            "297:\tlearn: 23.1384282\ttotal: 17.3s\tremaining: 40.6s\n",
            "298:\tlearn: 23.1335725\ttotal: 17.3s\tremaining: 40.6s\n",
            "299:\tlearn: 23.1290670\ttotal: 17.4s\tremaining: 40.5s\n",
            "300:\tlearn: 23.1257376\ttotal: 17.4s\tremaining: 40.4s\n",
            "301:\tlearn: 23.1224464\ttotal: 17.4s\tremaining: 40.3s\n",
            "302:\tlearn: 23.1163058\ttotal: 17.5s\tremaining: 40.2s\n",
            "303:\tlearn: 23.1104481\ttotal: 17.5s\tremaining: 40.2s\n",
            "304:\tlearn: 23.1070622\ttotal: 17.6s\tremaining: 40.1s\n",
            "305:\tlearn: 23.1042717\ttotal: 17.6s\tremaining: 40s\n",
            "306:\tlearn: 23.1009481\ttotal: 17.7s\tremaining: 39.9s\n",
            "307:\tlearn: 23.0980250\ttotal: 17.7s\tremaining: 39.8s\n",
            "308:\tlearn: 23.0934227\ttotal: 17.8s\tremaining: 39.7s\n",
            "309:\tlearn: 23.0870468\ttotal: 17.8s\tremaining: 39.6s\n",
            "310:\tlearn: 23.0831466\ttotal: 17.9s\tremaining: 39.6s\n",
            "311:\tlearn: 23.0740975\ttotal: 17.9s\tremaining: 39.5s\n",
            "312:\tlearn: 23.0712413\ttotal: 17.9s\tremaining: 39.4s\n",
            "313:\tlearn: 23.0668046\ttotal: 18s\tremaining: 39.3s\n",
            "314:\tlearn: 23.0640785\ttotal: 18s\tremaining: 39.2s\n",
            "315:\tlearn: 23.0554685\ttotal: 18.1s\tremaining: 39.2s\n",
            "316:\tlearn: 23.0518348\ttotal: 18.1s\tremaining: 39.1s\n",
            "317:\tlearn: 23.0476283\ttotal: 18.2s\tremaining: 39s\n",
            "318:\tlearn: 23.0446806\ttotal: 18.2s\tremaining: 38.9s\n",
            "319:\tlearn: 23.0425760\ttotal: 18.3s\tremaining: 38.8s\n",
            "320:\tlearn: 23.0400317\ttotal: 18.3s\tremaining: 38.8s\n",
            "321:\tlearn: 23.0334246\ttotal: 18.4s\tremaining: 38.7s\n",
            "322:\tlearn: 23.0299598\ttotal: 18.4s\tremaining: 38.6s\n",
            "323:\tlearn: 23.0276274\ttotal: 18.5s\tremaining: 38.5s\n",
            "324:\tlearn: 23.0203739\ttotal: 18.5s\tremaining: 38.4s\n",
            "325:\tlearn: 23.0160256\ttotal: 18.6s\tremaining: 38.4s\n",
            "326:\tlearn: 23.0102131\ttotal: 18.6s\tremaining: 38.3s\n",
            "327:\tlearn: 23.0080718\ttotal: 18.7s\tremaining: 38.2s\n",
            "328:\tlearn: 23.0047871\ttotal: 18.7s\tremaining: 38.1s\n",
            "329:\tlearn: 23.0026937\ttotal: 18.7s\tremaining: 38.1s\n",
            "330:\tlearn: 22.9989137\ttotal: 18.8s\tremaining: 38s\n",
            "331:\tlearn: 22.9952884\ttotal: 18.8s\tremaining: 37.9s\n",
            "332:\tlearn: 22.9902963\ttotal: 18.9s\tremaining: 37.8s\n",
            "333:\tlearn: 22.9850889\ttotal: 18.9s\tremaining: 37.7s\n",
            "334:\tlearn: 22.9817700\ttotal: 19s\tremaining: 37.7s\n",
            "335:\tlearn: 22.9780079\ttotal: 19s\tremaining: 37.6s\n",
            "336:\tlearn: 22.9753967\ttotal: 19.1s\tremaining: 37.5s\n",
            "337:\tlearn: 22.9706723\ttotal: 19.1s\tremaining: 37.5s\n",
            "338:\tlearn: 22.9688836\ttotal: 19.2s\tremaining: 37.4s\n",
            "339:\tlearn: 22.9655027\ttotal: 19.2s\tremaining: 37.3s\n",
            "340:\tlearn: 22.9626255\ttotal: 19.3s\tremaining: 37.2s\n",
            "341:\tlearn: 22.9609212\ttotal: 19.3s\tremaining: 37.2s\n",
            "342:\tlearn: 22.9587574\ttotal: 19.4s\tremaining: 37.1s\n",
            "343:\tlearn: 22.9549658\ttotal: 19.4s\tremaining: 37s\n",
            "344:\tlearn: 22.9502354\ttotal: 19.5s\tremaining: 37s\n",
            "345:\tlearn: 22.9455314\ttotal: 19.5s\tremaining: 36.9s\n",
            "346:\tlearn: 22.9439236\ttotal: 19.6s\tremaining: 36.8s\n",
            "347:\tlearn: 22.9386573\ttotal: 19.6s\tremaining: 36.7s\n",
            "348:\tlearn: 22.9361572\ttotal: 19.7s\tremaining: 36.7s\n",
            "349:\tlearn: 22.9309202\ttotal: 19.7s\tremaining: 36.6s\n",
            "350:\tlearn: 22.9282162\ttotal: 19.8s\tremaining: 36.5s\n",
            "351:\tlearn: 22.9258161\ttotal: 19.8s\tremaining: 36.5s\n",
            "352:\tlearn: 22.9208672\ttotal: 19.9s\tremaining: 36.4s\n",
            "353:\tlearn: 22.9180225\ttotal: 19.9s\tremaining: 36.3s\n",
            "354:\tlearn: 22.9144341\ttotal: 20s\tremaining: 36.3s\n",
            "355:\tlearn: 22.9097233\ttotal: 20s\tremaining: 36.2s\n",
            "356:\tlearn: 22.9073104\ttotal: 20.1s\tremaining: 36.1s\n",
            "357:\tlearn: 22.9055593\ttotal: 20.1s\tremaining: 36s\n",
            "358:\tlearn: 22.9038552\ttotal: 20.2s\tremaining: 36s\n",
            "359:\tlearn: 22.9006374\ttotal: 20.2s\tremaining: 35.9s\n",
            "360:\tlearn: 22.8976248\ttotal: 20.3s\tremaining: 35.9s\n",
            "361:\tlearn: 22.8952281\ttotal: 20.3s\tremaining: 35.8s\n",
            "362:\tlearn: 22.8927581\ttotal: 20.4s\tremaining: 35.7s\n",
            "363:\tlearn: 22.8874324\ttotal: 20.4s\tremaining: 35.7s\n",
            "364:\tlearn: 22.8854696\ttotal: 20.5s\tremaining: 35.6s\n",
            "365:\tlearn: 22.8831345\ttotal: 20.5s\tremaining: 35.5s\n",
            "366:\tlearn: 22.8806946\ttotal: 20.6s\tremaining: 35.5s\n",
            "367:\tlearn: 22.8792128\ttotal: 20.6s\tremaining: 35.4s\n",
            "368:\tlearn: 22.8755772\ttotal: 20.7s\tremaining: 35.3s\n",
            "369:\tlearn: 22.8719962\ttotal: 20.7s\tremaining: 35.3s\n",
            "370:\tlearn: 22.8696369\ttotal: 20.8s\tremaining: 35.2s\n",
            "371:\tlearn: 22.8680917\ttotal: 20.8s\tremaining: 35.1s\n",
            "372:\tlearn: 22.8644860\ttotal: 20.9s\tremaining: 35.1s\n",
            "373:\tlearn: 22.8619206\ttotal: 20.9s\tremaining: 35s\n",
            "374:\tlearn: 22.8569323\ttotal: 21s\tremaining: 35s\n",
            "375:\tlearn: 22.8554448\ttotal: 21s\tremaining: 34.9s\n",
            "376:\tlearn: 22.8515584\ttotal: 21.1s\tremaining: 34.8s\n",
            "377:\tlearn: 22.8502225\ttotal: 21.1s\tremaining: 34.7s\n",
            "378:\tlearn: 22.8488174\ttotal: 21.2s\tremaining: 34.7s\n",
            "379:\tlearn: 22.8452125\ttotal: 21.2s\tremaining: 34.6s\n",
            "380:\tlearn: 22.8435116\ttotal: 21.3s\tremaining: 34.6s\n",
            "381:\tlearn: 22.8421895\ttotal: 21.3s\tremaining: 34.5s\n",
            "382:\tlearn: 22.8396944\ttotal: 21.4s\tremaining: 34.4s\n",
            "383:\tlearn: 22.8364182\ttotal: 21.4s\tremaining: 34.4s\n",
            "384:\tlearn: 22.8326575\ttotal: 21.5s\tremaining: 34.3s\n",
            "385:\tlearn: 22.8301267\ttotal: 21.5s\tremaining: 34.2s\n",
            "386:\tlearn: 22.8288918\ttotal: 21.6s\tremaining: 34.2s\n",
            "387:\tlearn: 22.8270282\ttotal: 21.6s\tremaining: 34.1s\n",
            "388:\tlearn: 22.8238737\ttotal: 21.7s\tremaining: 34s\n",
            "389:\tlearn: 22.8209536\ttotal: 21.7s\tremaining: 34s\n",
            "390:\tlearn: 22.8177513\ttotal: 21.8s\tremaining: 33.9s\n",
            "391:\tlearn: 22.8156059\ttotal: 21.8s\tremaining: 33.9s\n",
            "392:\tlearn: 22.8134086\ttotal: 21.9s\tremaining: 33.8s\n",
            "393:\tlearn: 22.8112814\ttotal: 21.9s\tremaining: 33.7s\n",
            "394:\tlearn: 22.8084090\ttotal: 22s\tremaining: 33.7s\n",
            "395:\tlearn: 22.8050788\ttotal: 22s\tremaining: 33.6s\n",
            "396:\tlearn: 22.8016010\ttotal: 22.1s\tremaining: 33.5s\n",
            "397:\tlearn: 22.8005094\ttotal: 22.1s\tremaining: 33.5s\n",
            "398:\tlearn: 22.7984205\ttotal: 22.2s\tremaining: 33.4s\n",
            "399:\tlearn: 22.7953819\ttotal: 22.2s\tremaining: 33.4s\n",
            "400:\tlearn: 22.7938147\ttotal: 22.3s\tremaining: 33.3s\n",
            "401:\tlearn: 22.7899644\ttotal: 22.3s\tremaining: 33.2s\n",
            "402:\tlearn: 22.7877454\ttotal: 22.4s\tremaining: 33.2s\n",
            "403:\tlearn: 22.7849682\ttotal: 22.5s\tremaining: 33.1s\n",
            "404:\tlearn: 22.7835659\ttotal: 22.5s\tremaining: 33.1s\n",
            "405:\tlearn: 22.7808127\ttotal: 22.6s\tremaining: 33s\n",
            "406:\tlearn: 22.7781406\ttotal: 22.6s\tremaining: 32.9s\n",
            "407:\tlearn: 22.7757932\ttotal: 22.7s\tremaining: 32.9s\n",
            "408:\tlearn: 22.7748260\ttotal: 22.7s\tremaining: 32.8s\n",
            "409:\tlearn: 22.7722335\ttotal: 22.8s\tremaining: 32.8s\n",
            "410:\tlearn: 22.7705428\ttotal: 22.8s\tremaining: 32.7s\n",
            "411:\tlearn: 22.7691788\ttotal: 22.9s\tremaining: 32.6s\n",
            "412:\tlearn: 22.7658025\ttotal: 22.9s\tremaining: 32.6s\n",
            "413:\tlearn: 22.7632843\ttotal: 23s\tremaining: 32.5s\n",
            "414:\tlearn: 22.7612466\ttotal: 23s\tremaining: 32.4s\n",
            "415:\tlearn: 22.7601264\ttotal: 23.1s\tremaining: 32.4s\n",
            "416:\tlearn: 22.7585425\ttotal: 23.1s\tremaining: 32.3s\n",
            "417:\tlearn: 22.7561804\ttotal: 23.2s\tremaining: 32.3s\n",
            "418:\tlearn: 22.7550087\ttotal: 23.2s\tremaining: 32.2s\n",
            "419:\tlearn: 22.7527524\ttotal: 23.3s\tremaining: 32.1s\n",
            "420:\tlearn: 22.7505084\ttotal: 23.3s\tremaining: 32.1s\n",
            "421:\tlearn: 22.7492661\ttotal: 23.4s\tremaining: 32s\n",
            "422:\tlearn: 22.7484364\ttotal: 23.4s\tremaining: 32s\n",
            "423:\tlearn: 22.7464795\ttotal: 23.5s\tremaining: 31.9s\n",
            "424:\tlearn: 22.7451258\ttotal: 23.5s\tremaining: 31.9s\n",
            "425:\tlearn: 22.7436234\ttotal: 23.6s\tremaining: 31.8s\n",
            "426:\tlearn: 22.7427077\ttotal: 23.6s\tremaining: 31.7s\n",
            "427:\tlearn: 22.7403301\ttotal: 23.7s\tremaining: 31.7s\n",
            "428:\tlearn: 22.7385857\ttotal: 23.7s\tremaining: 31.6s\n",
            "429:\tlearn: 22.7368635\ttotal: 23.8s\tremaining: 31.5s\n",
            "430:\tlearn: 22.7356712\ttotal: 23.8s\tremaining: 31.5s\n",
            "431:\tlearn: 22.7337794\ttotal: 23.9s\tremaining: 31.4s\n",
            "432:\tlearn: 22.7315020\ttotal: 24s\tremaining: 31.4s\n",
            "433:\tlearn: 22.7293469\ttotal: 24s\tremaining: 31.3s\n",
            "434:\tlearn: 22.7284479\ttotal: 24.1s\tremaining: 31.2s\n",
            "435:\tlearn: 22.7265535\ttotal: 24.1s\tremaining: 31.2s\n",
            "436:\tlearn: 22.7250626\ttotal: 24.2s\tremaining: 31.1s\n",
            "437:\tlearn: 22.7231292\ttotal: 24.2s\tremaining: 31.1s\n",
            "438:\tlearn: 22.7216776\ttotal: 24.3s\tremaining: 31s\n",
            "439:\tlearn: 22.7199662\ttotal: 24.3s\tremaining: 30.9s\n",
            "440:\tlearn: 22.7187376\ttotal: 24.4s\tremaining: 30.9s\n",
            "441:\tlearn: 22.7174557\ttotal: 24.4s\tremaining: 30.8s\n",
            "442:\tlearn: 22.7166625\ttotal: 24.5s\tremaining: 30.8s\n",
            "443:\tlearn: 22.7160442\ttotal: 24.5s\tremaining: 30.7s\n",
            "444:\tlearn: 22.7141180\ttotal: 24.6s\tremaining: 30.6s\n",
            "445:\tlearn: 22.7123775\ttotal: 24.6s\tremaining: 30.6s\n",
            "446:\tlearn: 22.7110423\ttotal: 24.7s\tremaining: 30.5s\n",
            "447:\tlearn: 22.7093627\ttotal: 24.7s\tremaining: 30.5s\n",
            "448:\tlearn: 22.7082656\ttotal: 24.8s\tremaining: 30.4s\n",
            "449:\tlearn: 22.7059806\ttotal: 24.8s\tremaining: 30.3s\n",
            "450:\tlearn: 22.7041764\ttotal: 24.9s\tremaining: 30.3s\n",
            "451:\tlearn: 22.7019919\ttotal: 24.9s\tremaining: 30.2s\n",
            "452:\tlearn: 22.7004036\ttotal: 25s\tremaining: 30.2s\n",
            "453:\tlearn: 22.6986906\ttotal: 25s\tremaining: 30.1s\n",
            "454:\tlearn: 22.6970599\ttotal: 25.1s\tremaining: 30s\n",
            "455:\tlearn: 22.6958655\ttotal: 25.1s\tremaining: 30s\n",
            "456:\tlearn: 22.6951754\ttotal: 25.2s\tremaining: 29.9s\n",
            "457:\tlearn: 22.6939513\ttotal: 25.2s\tremaining: 29.9s\n",
            "458:\tlearn: 22.6928407\ttotal: 25.3s\tremaining: 29.8s\n",
            "459:\tlearn: 22.6921684\ttotal: 25.3s\tremaining: 29.7s\n",
            "460:\tlearn: 22.6907095\ttotal: 25.4s\tremaining: 29.6s\n",
            "461:\tlearn: 22.6896114\ttotal: 25.4s\tremaining: 29.6s\n",
            "462:\tlearn: 22.6883562\ttotal: 25.5s\tremaining: 29.5s\n",
            "463:\tlearn: 22.6864439\ttotal: 25.5s\tremaining: 29.5s\n",
            "464:\tlearn: 22.6848063\ttotal: 25.6s\tremaining: 29.4s\n",
            "465:\tlearn: 22.6838849\ttotal: 25.6s\tremaining: 29.3s\n",
            "466:\tlearn: 22.6828224\ttotal: 25.6s\tremaining: 29.3s\n",
            "467:\tlearn: 22.6815438\ttotal: 25.7s\tremaining: 29.2s\n",
            "468:\tlearn: 22.6807135\ttotal: 25.8s\tremaining: 29.2s\n",
            "469:\tlearn: 22.6794213\ttotal: 25.8s\tremaining: 29.1s\n",
            "470:\tlearn: 22.6781589\ttotal: 25.8s\tremaining: 29s\n",
            "471:\tlearn: 22.6768424\ttotal: 25.9s\tremaining: 29s\n",
            "472:\tlearn: 22.6759819\ttotal: 25.9s\tremaining: 28.9s\n",
            "473:\tlearn: 22.6753203\ttotal: 26s\tremaining: 28.8s\n",
            "474:\tlearn: 22.6735770\ttotal: 26s\tremaining: 28.8s\n",
            "475:\tlearn: 22.6723068\ttotal: 26.1s\tremaining: 28.7s\n",
            "476:\tlearn: 22.6713517\ttotal: 26.1s\tremaining: 28.6s\n",
            "477:\tlearn: 22.6701859\ttotal: 26.2s\tremaining: 28.6s\n",
            "478:\tlearn: 22.6688453\ttotal: 26.2s\tremaining: 28.5s\n",
            "479:\tlearn: 22.6677577\ttotal: 26.3s\tremaining: 28.5s\n",
            "480:\tlearn: 22.6664569\ttotal: 26.3s\tremaining: 28.4s\n",
            "481:\tlearn: 22.6652679\ttotal: 26.4s\tremaining: 28.3s\n",
            "482:\tlearn: 22.6642551\ttotal: 26.4s\tremaining: 28.3s\n",
            "483:\tlearn: 22.6634158\ttotal: 26.5s\tremaining: 28.2s\n",
            "484:\tlearn: 22.6627614\ttotal: 26.5s\tremaining: 28.2s\n",
            "485:\tlearn: 22.6621276\ttotal: 26.6s\tremaining: 28.1s\n",
            "486:\tlearn: 22.6613381\ttotal: 26.6s\tremaining: 28s\n",
            "487:\tlearn: 22.6603443\ttotal: 26.7s\tremaining: 28s\n",
            "488:\tlearn: 22.6592398\ttotal: 26.7s\tremaining: 27.9s\n",
            "489:\tlearn: 22.6590223\ttotal: 26.7s\tremaining: 27.8s\n",
            "490:\tlearn: 22.6577325\ttotal: 26.8s\tremaining: 27.8s\n",
            "491:\tlearn: 22.6565313\ttotal: 26.8s\tremaining: 27.7s\n",
            "492:\tlearn: 22.6556710\ttotal: 26.9s\tremaining: 27.7s\n",
            "493:\tlearn: 22.6546445\ttotal: 26.9s\tremaining: 27.6s\n",
            "494:\tlearn: 22.6536466\ttotal: 27s\tremaining: 27.5s\n",
            "495:\tlearn: 22.6523953\ttotal: 27s\tremaining: 27.5s\n",
            "496:\tlearn: 22.6517437\ttotal: 27.1s\tremaining: 27.4s\n",
            "497:\tlearn: 22.6508380\ttotal: 27.1s\tremaining: 27.3s\n",
            "498:\tlearn: 22.6498091\ttotal: 27.2s\tremaining: 27.3s\n",
            "499:\tlearn: 22.6485741\ttotal: 27.3s\tremaining: 27.3s\n",
            "500:\tlearn: 22.6478749\ttotal: 27.4s\tremaining: 27.2s\n",
            "501:\tlearn: 22.6477988\ttotal: 27.4s\tremaining: 27.2s\n",
            "502:\tlearn: 22.6471301\ttotal: 27.5s\tremaining: 27.2s\n",
            "503:\tlearn: 22.6463559\ttotal: 27.6s\tremaining: 27.2s\n",
            "504:\tlearn: 22.6457080\ttotal: 27.7s\tremaining: 27.2s\n",
            "505:\tlearn: 22.6444227\ttotal: 27.8s\tremaining: 27.1s\n",
            "506:\tlearn: 22.6440497\ttotal: 27.9s\tremaining: 27.1s\n",
            "507:\tlearn: 22.6432707\ttotal: 28s\tremaining: 27.1s\n",
            "508:\tlearn: 22.6424047\ttotal: 28.1s\tremaining: 27.1s\n",
            "509:\tlearn: 22.6413136\ttotal: 28.2s\tremaining: 27.1s\n",
            "510:\tlearn: 22.6407689\ttotal: 28.3s\tremaining: 27s\n",
            "511:\tlearn: 22.6398907\ttotal: 28.4s\tremaining: 27s\n",
            "512:\tlearn: 22.6391643\ttotal: 28.4s\tremaining: 27s\n",
            "513:\tlearn: 22.6384154\ttotal: 28.5s\tremaining: 27s\n",
            "514:\tlearn: 22.6375196\ttotal: 28.6s\tremaining: 27s\n",
            "515:\tlearn: 22.6365563\ttotal: 28.7s\tremaining: 26.9s\n",
            "516:\tlearn: 22.6357188\ttotal: 28.8s\tremaining: 26.9s\n",
            "517:\tlearn: 22.6348894\ttotal: 28.9s\tremaining: 26.9s\n",
            "518:\tlearn: 22.6342197\ttotal: 29s\tremaining: 26.9s\n",
            "519:\tlearn: 22.6339039\ttotal: 29.1s\tremaining: 26.9s\n",
            "520:\tlearn: 22.6333715\ttotal: 29.2s\tremaining: 26.8s\n",
            "521:\tlearn: 22.6326415\ttotal: 29.3s\tremaining: 26.8s\n",
            "522:\tlearn: 22.6320404\ttotal: 29.4s\tremaining: 26.8s\n",
            "523:\tlearn: 22.6312369\ttotal: 29.5s\tremaining: 26.8s\n",
            "524:\tlearn: 22.6309212\ttotal: 29.5s\tremaining: 26.7s\n",
            "525:\tlearn: 22.6300145\ttotal: 29.6s\tremaining: 26.7s\n",
            "526:\tlearn: 22.6297110\ttotal: 29.7s\tremaining: 26.7s\n",
            "527:\tlearn: 22.6288269\ttotal: 29.8s\tremaining: 26.6s\n",
            "528:\tlearn: 22.6282018\ttotal: 29.9s\tremaining: 26.6s\n",
            "529:\tlearn: 22.6277675\ttotal: 30s\tremaining: 26.6s\n",
            "530:\tlearn: 22.6266828\ttotal: 30s\tremaining: 26.5s\n",
            "531:\tlearn: 22.6258417\ttotal: 30.1s\tremaining: 26.4s\n",
            "532:\tlearn: 22.6251740\ttotal: 30.1s\tremaining: 26.4s\n",
            "533:\tlearn: 22.6243549\ttotal: 30.2s\tremaining: 26.3s\n",
            "534:\tlearn: 22.6241929\ttotal: 30.2s\tremaining: 26.2s\n",
            "535:\tlearn: 22.6238010\ttotal: 30.2s\tremaining: 26.2s\n",
            "536:\tlearn: 22.6232560\ttotal: 30.3s\tremaining: 26.1s\n",
            "537:\tlearn: 22.6228601\ttotal: 30.3s\tremaining: 26.1s\n",
            "538:\tlearn: 22.6222752\ttotal: 30.4s\tremaining: 26s\n",
            "539:\tlearn: 22.6218093\ttotal: 30.4s\tremaining: 25.9s\n",
            "540:\tlearn: 22.6213059\ttotal: 30.5s\tremaining: 25.9s\n",
            "541:\tlearn: 22.6210335\ttotal: 30.5s\tremaining: 25.8s\n",
            "542:\tlearn: 22.6204326\ttotal: 30.6s\tremaining: 25.7s\n",
            "543:\tlearn: 22.6198430\ttotal: 30.6s\tremaining: 25.7s\n",
            "544:\tlearn: 22.6197184\ttotal: 30.7s\tremaining: 25.6s\n",
            "545:\tlearn: 22.6190029\ttotal: 30.7s\tremaining: 25.5s\n",
            "546:\tlearn: 22.6184463\ttotal: 30.8s\tremaining: 25.5s\n",
            "547:\tlearn: 22.6178873\ttotal: 30.8s\tremaining: 25.4s\n",
            "548:\tlearn: 22.6173435\ttotal: 30.9s\tremaining: 25.4s\n",
            "549:\tlearn: 22.6163970\ttotal: 30.9s\tremaining: 25.3s\n",
            "550:\tlearn: 22.6156332\ttotal: 31s\tremaining: 25.2s\n",
            "551:\tlearn: 22.6150489\ttotal: 31s\tremaining: 25.2s\n",
            "552:\tlearn: 22.6144932\ttotal: 31s\tremaining: 25.1s\n",
            "553:\tlearn: 22.6140256\ttotal: 31.1s\tremaining: 25s\n",
            "554:\tlearn: 22.6132911\ttotal: 31.1s\tremaining: 25s\n",
            "555:\tlearn: 22.6127198\ttotal: 31.2s\tremaining: 24.9s\n",
            "556:\tlearn: 22.6120368\ttotal: 31.2s\tremaining: 24.8s\n",
            "557:\tlearn: 22.6114394\ttotal: 31.3s\tremaining: 24.8s\n",
            "558:\tlearn: 22.6107810\ttotal: 31.3s\tremaining: 24.7s\n",
            "559:\tlearn: 22.6103864\ttotal: 31.4s\tremaining: 24.6s\n",
            "560:\tlearn: 22.6099111\ttotal: 31.4s\tremaining: 24.6s\n",
            "561:\tlearn: 22.6095626\ttotal: 31.5s\tremaining: 24.5s\n",
            "562:\tlearn: 22.6090197\ttotal: 31.5s\tremaining: 24.5s\n",
            "563:\tlearn: 22.6085444\ttotal: 31.6s\tremaining: 24.4s\n",
            "564:\tlearn: 22.6082179\ttotal: 31.6s\tremaining: 24.3s\n",
            "565:\tlearn: 22.6077887\ttotal: 31.7s\tremaining: 24.3s\n",
            "566:\tlearn: 22.6069952\ttotal: 31.7s\tremaining: 24.2s\n",
            "567:\tlearn: 22.6063474\ttotal: 31.8s\tremaining: 24.2s\n",
            "568:\tlearn: 22.6058798\ttotal: 31.8s\tremaining: 24.1s\n",
            "569:\tlearn: 22.6057410\ttotal: 31.9s\tremaining: 24s\n",
            "570:\tlearn: 22.6050953\ttotal: 31.9s\tremaining: 24s\n",
            "571:\tlearn: 22.6045214\ttotal: 31.9s\tremaining: 23.9s\n",
            "572:\tlearn: 22.6039551\ttotal: 32s\tremaining: 23.8s\n",
            "573:\tlearn: 22.6035967\ttotal: 32s\tremaining: 23.8s\n",
            "574:\tlearn: 22.6031668\ttotal: 32.1s\tremaining: 23.7s\n",
            "575:\tlearn: 22.6029411\ttotal: 32.1s\tremaining: 23.7s\n",
            "576:\tlearn: 22.6025152\ttotal: 32.2s\tremaining: 23.6s\n",
            "577:\tlearn: 22.6019857\ttotal: 32.2s\tremaining: 23.5s\n",
            "578:\tlearn: 22.6016716\ttotal: 32.3s\tremaining: 23.5s\n",
            "579:\tlearn: 22.6011348\ttotal: 32.3s\tremaining: 23.4s\n",
            "580:\tlearn: 22.6006580\ttotal: 32.4s\tremaining: 23.4s\n",
            "581:\tlearn: 22.6003247\ttotal: 32.4s\tremaining: 23.3s\n",
            "582:\tlearn: 22.6000467\ttotal: 32.5s\tremaining: 23.2s\n",
            "583:\tlearn: 22.5996099\ttotal: 32.5s\tremaining: 23.2s\n",
            "584:\tlearn: 22.5991840\ttotal: 32.6s\tremaining: 23.1s\n",
            "585:\tlearn: 22.5989200\ttotal: 32.6s\tremaining: 23s\n",
            "586:\tlearn: 22.5983830\ttotal: 32.7s\tremaining: 23s\n",
            "587:\tlearn: 22.5980449\ttotal: 32.7s\tremaining: 22.9s\n",
            "588:\tlearn: 22.5974858\ttotal: 32.8s\tremaining: 22.9s\n",
            "589:\tlearn: 22.5971533\ttotal: 32.8s\tremaining: 22.8s\n",
            "590:\tlearn: 22.5968153\ttotal: 32.9s\tremaining: 22.7s\n",
            "591:\tlearn: 22.5964598\ttotal: 32.9s\tremaining: 22.7s\n",
            "592:\tlearn: 22.5961632\ttotal: 32.9s\tremaining: 22.6s\n",
            "593:\tlearn: 22.5957191\ttotal: 33s\tremaining: 22.6s\n",
            "594:\tlearn: 22.5952798\ttotal: 33s\tremaining: 22.5s\n",
            "595:\tlearn: 22.5950338\ttotal: 33.1s\tremaining: 22.4s\n",
            "596:\tlearn: 22.5945878\ttotal: 33.1s\tremaining: 22.4s\n",
            "597:\tlearn: 22.5943486\ttotal: 33.2s\tremaining: 22.3s\n",
            "598:\tlearn: 22.5941193\ttotal: 33.2s\tremaining: 22.2s\n",
            "599:\tlearn: 22.5936781\ttotal: 33.3s\tremaining: 22.2s\n",
            "600:\tlearn: 22.5933315\ttotal: 33.3s\tremaining: 22.1s\n",
            "601:\tlearn: 22.5930212\ttotal: 33.4s\tremaining: 22.1s\n",
            "602:\tlearn: 22.5925988\ttotal: 33.4s\tremaining: 22s\n",
            "603:\tlearn: 22.5922880\ttotal: 33.5s\tremaining: 21.9s\n",
            "604:\tlearn: 22.5917834\ttotal: 33.5s\tremaining: 21.9s\n",
            "605:\tlearn: 22.5915383\ttotal: 33.6s\tremaining: 21.8s\n",
            "606:\tlearn: 22.5912098\ttotal: 33.6s\tremaining: 21.8s\n",
            "607:\tlearn: 22.5906201\ttotal: 33.7s\tremaining: 21.7s\n",
            "608:\tlearn: 22.5900662\ttotal: 33.7s\tremaining: 21.6s\n",
            "609:\tlearn: 22.5897044\ttotal: 33.8s\tremaining: 21.6s\n",
            "610:\tlearn: 22.5894587\ttotal: 33.8s\tremaining: 21.5s\n",
            "611:\tlearn: 22.5892031\ttotal: 33.9s\tremaining: 21.5s\n",
            "612:\tlearn: 22.5889477\ttotal: 33.9s\tremaining: 21.4s\n",
            "613:\tlearn: 22.5887340\ttotal: 34s\tremaining: 21.3s\n",
            "614:\tlearn: 22.5885651\ttotal: 34s\tremaining: 21.3s\n",
            "615:\tlearn: 22.5881794\ttotal: 34.1s\tremaining: 21.2s\n",
            "616:\tlearn: 22.5880312\ttotal: 34.1s\tremaining: 21.2s\n",
            "617:\tlearn: 22.5876061\ttotal: 34.2s\tremaining: 21.1s\n",
            "618:\tlearn: 22.5871539\ttotal: 34.2s\tremaining: 21.1s\n",
            "619:\tlearn: 22.5867074\ttotal: 34.3s\tremaining: 21s\n",
            "620:\tlearn: 22.5866136\ttotal: 34.3s\tremaining: 20.9s\n",
            "621:\tlearn: 22.5863848\ttotal: 34.4s\tremaining: 20.9s\n",
            "622:\tlearn: 22.5859040\ttotal: 34.4s\tremaining: 20.8s\n",
            "623:\tlearn: 22.5856784\ttotal: 34.5s\tremaining: 20.8s\n",
            "624:\tlearn: 22.5853849\ttotal: 34.5s\tremaining: 20.7s\n",
            "625:\tlearn: 22.5851463\ttotal: 34.6s\tremaining: 20.7s\n",
            "626:\tlearn: 22.5849045\ttotal: 34.6s\tremaining: 20.6s\n",
            "627:\tlearn: 22.5847025\ttotal: 34.7s\tremaining: 20.6s\n",
            "628:\tlearn: 22.5842354\ttotal: 34.7s\tremaining: 20.5s\n",
            "629:\tlearn: 22.5840812\ttotal: 34.8s\tremaining: 20.4s\n",
            "630:\tlearn: 22.5837257\ttotal: 34.8s\tremaining: 20.4s\n",
            "631:\tlearn: 22.5834174\ttotal: 34.9s\tremaining: 20.3s\n",
            "632:\tlearn: 22.5830983\ttotal: 34.9s\tremaining: 20.3s\n",
            "633:\tlearn: 22.5827648\ttotal: 35s\tremaining: 20.2s\n",
            "634:\tlearn: 22.5825154\ttotal: 35s\tremaining: 20.1s\n",
            "635:\tlearn: 22.5821426\ttotal: 35.1s\tremaining: 20.1s\n",
            "636:\tlearn: 22.5820610\ttotal: 35.1s\tremaining: 20s\n",
            "637:\tlearn: 22.5818104\ttotal: 35.2s\tremaining: 20s\n",
            "638:\tlearn: 22.5814480\ttotal: 35.2s\tremaining: 19.9s\n",
            "639:\tlearn: 22.5809370\ttotal: 35.3s\tremaining: 19.8s\n",
            "640:\tlearn: 22.5808719\ttotal: 35.3s\tremaining: 19.8s\n",
            "641:\tlearn: 22.5807926\ttotal: 35.3s\tremaining: 19.7s\n",
            "642:\tlearn: 22.5805962\ttotal: 35.4s\tremaining: 19.7s\n",
            "643:\tlearn: 22.5803015\ttotal: 35.5s\tremaining: 19.6s\n",
            "644:\tlearn: 22.5801557\ttotal: 35.5s\tremaining: 19.5s\n",
            "645:\tlearn: 22.5799392\ttotal: 35.5s\tremaining: 19.5s\n",
            "646:\tlearn: 22.5796223\ttotal: 35.6s\tremaining: 19.4s\n",
            "647:\tlearn: 22.5792899\ttotal: 35.7s\tremaining: 19.4s\n",
            "648:\tlearn: 22.5790584\ttotal: 35.7s\tremaining: 19.3s\n",
            "649:\tlearn: 22.5787856\ttotal: 35.8s\tremaining: 19.3s\n",
            "650:\tlearn: 22.5784506\ttotal: 35.8s\tremaining: 19.2s\n",
            "651:\tlearn: 22.5780857\ttotal: 35.8s\tremaining: 19.1s\n",
            "652:\tlearn: 22.5776533\ttotal: 35.9s\tremaining: 19.1s\n",
            "653:\tlearn: 22.5774329\ttotal: 35.9s\tremaining: 19s\n",
            "654:\tlearn: 22.5773363\ttotal: 36s\tremaining: 19s\n",
            "655:\tlearn: 22.5772244\ttotal: 36s\tremaining: 18.9s\n",
            "656:\tlearn: 22.5768951\ttotal: 36.1s\tremaining: 18.8s\n",
            "657:\tlearn: 22.5765475\ttotal: 36.1s\tremaining: 18.8s\n",
            "658:\tlearn: 22.5761197\ttotal: 36.2s\tremaining: 18.7s\n",
            "659:\tlearn: 22.5759142\ttotal: 36.2s\tremaining: 18.7s\n",
            "660:\tlearn: 22.5756968\ttotal: 36.3s\tremaining: 18.6s\n",
            "661:\tlearn: 22.5756020\ttotal: 36.3s\tremaining: 18.5s\n",
            "662:\tlearn: 22.5753926\ttotal: 36.4s\tremaining: 18.5s\n",
            "663:\tlearn: 22.5750592\ttotal: 36.4s\tremaining: 18.4s\n",
            "664:\tlearn: 22.5749187\ttotal: 36.5s\tremaining: 18.4s\n",
            "665:\tlearn: 22.5745972\ttotal: 36.5s\tremaining: 18.3s\n",
            "666:\tlearn: 22.5744329\ttotal: 36.5s\tremaining: 18.2s\n",
            "667:\tlearn: 22.5743116\ttotal: 36.6s\tremaining: 18.2s\n",
            "668:\tlearn: 22.5739729\ttotal: 36.6s\tremaining: 18.1s\n",
            "669:\tlearn: 22.5739070\ttotal: 36.7s\tremaining: 18.1s\n",
            "670:\tlearn: 22.5735903\ttotal: 36.7s\tremaining: 18s\n",
            "671:\tlearn: 22.5734764\ttotal: 36.8s\tremaining: 18s\n",
            "672:\tlearn: 22.5733069\ttotal: 36.8s\tremaining: 17.9s\n",
            "673:\tlearn: 22.5731511\ttotal: 36.9s\tremaining: 17.8s\n",
            "674:\tlearn: 22.5728764\ttotal: 36.9s\tremaining: 17.8s\n",
            "675:\tlearn: 22.5726225\ttotal: 37s\tremaining: 17.7s\n",
            "676:\tlearn: 22.5725829\ttotal: 37s\tremaining: 17.7s\n",
            "677:\tlearn: 22.5723056\ttotal: 37.1s\tremaining: 17.6s\n",
            "678:\tlearn: 22.5721499\ttotal: 37.1s\tremaining: 17.6s\n",
            "679:\tlearn: 22.5720309\ttotal: 37.2s\tremaining: 17.5s\n",
            "680:\tlearn: 22.5717306\ttotal: 37.2s\tremaining: 17.4s\n",
            "681:\tlearn: 22.5716916\ttotal: 37.3s\tremaining: 17.4s\n",
            "682:\tlearn: 22.5713832\ttotal: 37.3s\tremaining: 17.3s\n",
            "683:\tlearn: 22.5710155\ttotal: 37.4s\tremaining: 17.3s\n",
            "684:\tlearn: 22.5709307\ttotal: 37.4s\tremaining: 17.2s\n",
            "685:\tlearn: 22.5707809\ttotal: 37.5s\tremaining: 17.2s\n",
            "686:\tlearn: 22.5703850\ttotal: 37.5s\tremaining: 17.1s\n",
            "687:\tlearn: 22.5701653\ttotal: 37.6s\tremaining: 17.1s\n",
            "688:\tlearn: 22.5698650\ttotal: 37.6s\tremaining: 17s\n",
            "689:\tlearn: 22.5697090\ttotal: 37.7s\tremaining: 16.9s\n",
            "690:\tlearn: 22.5695450\ttotal: 37.8s\tremaining: 16.9s\n",
            "691:\tlearn: 22.5694690\ttotal: 37.8s\tremaining: 16.8s\n",
            "692:\tlearn: 22.5690555\ttotal: 37.9s\tremaining: 16.8s\n",
            "693:\tlearn: 22.5687863\ttotal: 37.9s\tremaining: 16.7s\n",
            "694:\tlearn: 22.5687462\ttotal: 38s\tremaining: 16.7s\n",
            "695:\tlearn: 22.5685700\ttotal: 38s\tremaining: 16.6s\n",
            "696:\tlearn: 22.5683693\ttotal: 38.1s\tremaining: 16.5s\n",
            "697:\tlearn: 22.5683305\ttotal: 38.1s\tremaining: 16.5s\n",
            "698:\tlearn: 22.5680374\ttotal: 38.2s\tremaining: 16.4s\n",
            "699:\tlearn: 22.5679996\ttotal: 38.2s\tremaining: 16.4s\n",
            "700:\tlearn: 22.5679670\ttotal: 38.3s\tremaining: 16.3s\n",
            "701:\tlearn: 22.5679026\ttotal: 38.3s\tremaining: 16.3s\n",
            "702:\tlearn: 22.5676145\ttotal: 38.4s\tremaining: 16.2s\n",
            "703:\tlearn: 22.5674525\ttotal: 38.4s\tremaining: 16.2s\n",
            "704:\tlearn: 22.5671708\ttotal: 38.5s\tremaining: 16.1s\n",
            "705:\tlearn: 22.5671257\ttotal: 38.5s\tremaining: 16s\n",
            "706:\tlearn: 22.5668887\ttotal: 38.6s\tremaining: 16s\n",
            "707:\tlearn: 22.5667807\ttotal: 38.6s\tremaining: 15.9s\n",
            "708:\tlearn: 22.5666393\ttotal: 38.7s\tremaining: 15.9s\n",
            "709:\tlearn: 22.5664877\ttotal: 38.7s\tremaining: 15.8s\n",
            "710:\tlearn: 22.5664508\ttotal: 38.8s\tremaining: 15.8s\n",
            "711:\tlearn: 22.5662602\ttotal: 38.8s\tremaining: 15.7s\n",
            "712:\tlearn: 22.5660083\ttotal: 38.9s\tremaining: 15.6s\n",
            "713:\tlearn: 22.5658811\ttotal: 38.9s\tremaining: 15.6s\n",
            "714:\tlearn: 22.5656272\ttotal: 39s\tremaining: 15.5s\n",
            "715:\tlearn: 22.5654264\ttotal: 39s\tremaining: 15.5s\n",
            "716:\tlearn: 22.5652823\ttotal: 39.1s\tremaining: 15.4s\n",
            "717:\tlearn: 22.5651487\ttotal: 39.1s\tremaining: 15.4s\n",
            "718:\tlearn: 22.5650134\ttotal: 39.2s\tremaining: 15.3s\n",
            "719:\tlearn: 22.5648787\ttotal: 39.2s\tremaining: 15.3s\n",
            "720:\tlearn: 22.5647231\ttotal: 39.3s\tremaining: 15.2s\n",
            "721:\tlearn: 22.5645115\ttotal: 39.3s\tremaining: 15.1s\n",
            "722:\tlearn: 22.5643524\ttotal: 39.4s\tremaining: 15.1s\n",
            "723:\tlearn: 22.5641483\ttotal: 39.4s\tremaining: 15s\n",
            "724:\tlearn: 22.5638558\ttotal: 39.5s\tremaining: 15s\n",
            "725:\tlearn: 22.5635881\ttotal: 39.5s\tremaining: 14.9s\n",
            "726:\tlearn: 22.5634299\ttotal: 39.6s\tremaining: 14.9s\n",
            "727:\tlearn: 22.5633392\ttotal: 39.7s\tremaining: 14.8s\n",
            "728:\tlearn: 22.5631137\ttotal: 39.7s\tremaining: 14.8s\n",
            "729:\tlearn: 22.5629581\ttotal: 39.8s\tremaining: 14.7s\n",
            "730:\tlearn: 22.5628372\ttotal: 39.8s\tremaining: 14.7s\n",
            "731:\tlearn: 22.5627392\ttotal: 39.9s\tremaining: 14.6s\n",
            "732:\tlearn: 22.5626585\ttotal: 40s\tremaining: 14.6s\n",
            "733:\tlearn: 22.5625430\ttotal: 40.1s\tremaining: 14.5s\n",
            "734:\tlearn: 22.5623646\ttotal: 40.2s\tremaining: 14.5s\n",
            "735:\tlearn: 22.5623221\ttotal: 40.2s\tremaining: 14.4s\n",
            "736:\tlearn: 22.5621035\ttotal: 40.3s\tremaining: 14.4s\n",
            "737:\tlearn: 22.5619712\ttotal: 40.4s\tremaining: 14.4s\n",
            "738:\tlearn: 22.5617210\ttotal: 40.5s\tremaining: 14.3s\n",
            "739:\tlearn: 22.5615290\ttotal: 40.6s\tremaining: 14.3s\n",
            "740:\tlearn: 22.5614983\ttotal: 40.7s\tremaining: 14.2s\n",
            "741:\tlearn: 22.5613632\ttotal: 40.8s\tremaining: 14.2s\n",
            "742:\tlearn: 22.5613305\ttotal: 40.9s\tremaining: 14.1s\n",
            "743:\tlearn: 22.5611380\ttotal: 41s\tremaining: 14.1s\n",
            "744:\tlearn: 22.5611063\ttotal: 41s\tremaining: 14s\n",
            "745:\tlearn: 22.5608264\ttotal: 41.1s\tremaining: 14s\n",
            "746:\tlearn: 22.5606832\ttotal: 41.2s\tremaining: 14s\n",
            "747:\tlearn: 22.5606505\ttotal: 41.3s\tremaining: 13.9s\n",
            "748:\tlearn: 22.5606200\ttotal: 41.4s\tremaining: 13.9s\n",
            "749:\tlearn: 22.5604655\ttotal: 41.5s\tremaining: 13.8s\n",
            "750:\tlearn: 22.5602489\ttotal: 41.6s\tremaining: 13.8s\n",
            "751:\tlearn: 22.5601608\ttotal: 41.7s\tremaining: 13.7s\n",
            "752:\tlearn: 22.5599426\ttotal: 41.8s\tremaining: 13.7s\n",
            "753:\tlearn: 22.5597548\ttotal: 41.9s\tremaining: 13.7s\n",
            "754:\tlearn: 22.5595921\ttotal: 42s\tremaining: 13.6s\n",
            "755:\tlearn: 22.5593523\ttotal: 42.1s\tremaining: 13.6s\n",
            "756:\tlearn: 22.5591770\ttotal: 42.2s\tremaining: 13.5s\n",
            "757:\tlearn: 22.5591155\ttotal: 42.3s\tremaining: 13.5s\n",
            "758:\tlearn: 22.5590115\ttotal: 42.4s\tremaining: 13.4s\n",
            "759:\tlearn: 22.5587991\ttotal: 42.4s\tremaining: 13.4s\n",
            "760:\tlearn: 22.5586914\ttotal: 42.5s\tremaining: 13.4s\n",
            "761:\tlearn: 22.5585616\ttotal: 42.6s\tremaining: 13.3s\n",
            "762:\tlearn: 22.5585060\ttotal: 42.7s\tremaining: 13.3s\n",
            "763:\tlearn: 22.5583326\ttotal: 42.7s\tremaining: 13.2s\n",
            "764:\tlearn: 22.5581055\ttotal: 42.8s\tremaining: 13.1s\n",
            "765:\tlearn: 22.5579227\ttotal: 42.8s\tremaining: 13.1s\n",
            "766:\tlearn: 22.5578296\ttotal: 42.9s\tremaining: 13s\n",
            "767:\tlearn: 22.5577836\ttotal: 42.9s\tremaining: 13s\n",
            "768:\tlearn: 22.5576179\ttotal: 43s\tremaining: 12.9s\n",
            "769:\tlearn: 22.5574629\ttotal: 43s\tremaining: 12.9s\n",
            "770:\tlearn: 22.5573676\ttotal: 43.1s\tremaining: 12.8s\n",
            "771:\tlearn: 22.5571804\ttotal: 43.1s\tremaining: 12.7s\n",
            "772:\tlearn: 22.5570258\ttotal: 43.2s\tremaining: 12.7s\n",
            "773:\tlearn: 22.5569224\ttotal: 43.2s\tremaining: 12.6s\n",
            "774:\tlearn: 22.5567475\ttotal: 43.3s\tremaining: 12.6s\n",
            "775:\tlearn: 22.5566268\ttotal: 43.3s\tremaining: 12.5s\n",
            "776:\tlearn: 22.5564584\ttotal: 43.4s\tremaining: 12.4s\n",
            "777:\tlearn: 22.5564268\ttotal: 43.4s\tremaining: 12.4s\n",
            "778:\tlearn: 22.5564041\ttotal: 43.4s\tremaining: 12.3s\n",
            "779:\tlearn: 22.5563018\ttotal: 43.5s\tremaining: 12.3s\n",
            "780:\tlearn: 22.5560485\ttotal: 43.5s\tremaining: 12.2s\n",
            "781:\tlearn: 22.5559763\ttotal: 43.6s\tremaining: 12.2s\n",
            "782:\tlearn: 22.5558866\ttotal: 43.6s\tremaining: 12.1s\n",
            "783:\tlearn: 22.5557993\ttotal: 43.7s\tremaining: 12s\n",
            "784:\tlearn: 22.5557084\ttotal: 43.7s\tremaining: 12s\n",
            "785:\tlearn: 22.5555563\ttotal: 43.8s\tremaining: 11.9s\n",
            "786:\tlearn: 22.5553688\ttotal: 43.8s\tremaining: 11.9s\n",
            "787:\tlearn: 22.5552598\ttotal: 43.9s\tremaining: 11.8s\n",
            "788:\tlearn: 22.5550814\ttotal: 43.9s\tremaining: 11.7s\n",
            "789:\tlearn: 22.5548823\ttotal: 44s\tremaining: 11.7s\n",
            "790:\tlearn: 22.5547760\ttotal: 44s\tremaining: 11.6s\n",
            "791:\tlearn: 22.5545805\ttotal: 44.1s\tremaining: 11.6s\n",
            "792:\tlearn: 22.5544530\ttotal: 44.1s\tremaining: 11.5s\n",
            "793:\tlearn: 22.5543737\ttotal: 44.2s\tremaining: 11.5s\n",
            "794:\tlearn: 22.5543362\ttotal: 44.2s\tremaining: 11.4s\n",
            "795:\tlearn: 22.5541916\ttotal: 44.3s\tremaining: 11.3s\n",
            "796:\tlearn: 22.5540884\ttotal: 44.3s\tremaining: 11.3s\n",
            "797:\tlearn: 22.5539547\ttotal: 44.3s\tremaining: 11.2s\n",
            "798:\tlearn: 22.5537867\ttotal: 44.4s\tremaining: 11.2s\n",
            "799:\tlearn: 22.5537295\ttotal: 44.4s\tremaining: 11.1s\n",
            "800:\tlearn: 22.5535452\ttotal: 44.5s\tremaining: 11.1s\n",
            "801:\tlearn: 22.5534610\ttotal: 44.5s\tremaining: 11s\n",
            "802:\tlearn: 22.5533993\ttotal: 44.6s\tremaining: 10.9s\n",
            "803:\tlearn: 22.5532451\ttotal: 44.6s\tremaining: 10.9s\n",
            "804:\tlearn: 22.5530949\ttotal: 44.7s\tremaining: 10.8s\n",
            "805:\tlearn: 22.5530598\ttotal: 44.7s\tremaining: 10.8s\n",
            "806:\tlearn: 22.5529033\ttotal: 44.8s\tremaining: 10.7s\n",
            "807:\tlearn: 22.5528058\ttotal: 44.8s\tremaining: 10.6s\n",
            "808:\tlearn: 22.5526729\ttotal: 44.8s\tremaining: 10.6s\n",
            "809:\tlearn: 22.5525320\ttotal: 44.9s\tremaining: 10.5s\n",
            "810:\tlearn: 22.5524209\ttotal: 45s\tremaining: 10.5s\n",
            "811:\tlearn: 22.5522160\ttotal: 45s\tremaining: 10.4s\n",
            "812:\tlearn: 22.5520760\ttotal: 45.1s\tremaining: 10.4s\n",
            "813:\tlearn: 22.5519570\ttotal: 45.1s\tremaining: 10.3s\n",
            "814:\tlearn: 22.5518174\ttotal: 45.2s\tremaining: 10.2s\n",
            "815:\tlearn: 22.5516647\ttotal: 45.2s\tremaining: 10.2s\n",
            "816:\tlearn: 22.5515994\ttotal: 45.3s\tremaining: 10.1s\n",
            "817:\tlearn: 22.5515176\ttotal: 45.3s\tremaining: 10.1s\n",
            "818:\tlearn: 22.5514468\ttotal: 45.3s\tremaining: 10s\n",
            "819:\tlearn: 22.5513883\ttotal: 45.4s\tremaining: 9.96s\n",
            "820:\tlearn: 22.5513171\ttotal: 45.4s\tremaining: 9.91s\n",
            "821:\tlearn: 22.5511500\ttotal: 45.5s\tremaining: 9.85s\n",
            "822:\tlearn: 22.5510066\ttotal: 45.5s\tremaining: 9.79s\n",
            "823:\tlearn: 22.5508808\ttotal: 45.6s\tremaining: 9.74s\n",
            "824:\tlearn: 22.5508495\ttotal: 45.6s\tremaining: 9.68s\n",
            "825:\tlearn: 22.5508154\ttotal: 45.7s\tremaining: 9.63s\n",
            "826:\tlearn: 22.5507997\ttotal: 45.7s\tremaining: 9.57s\n",
            "827:\tlearn: 22.5506430\ttotal: 45.8s\tremaining: 9.51s\n",
            "828:\tlearn: 22.5505195\ttotal: 45.8s\tremaining: 9.46s\n",
            "829:\tlearn: 22.5503798\ttotal: 45.9s\tremaining: 9.4s\n",
            "830:\tlearn: 22.5503378\ttotal: 46s\tremaining: 9.35s\n",
            "831:\tlearn: 22.5502710\ttotal: 46s\tremaining: 9.29s\n",
            "832:\tlearn: 22.5502285\ttotal: 46.1s\tremaining: 9.24s\n",
            "833:\tlearn: 22.5501311\ttotal: 46.1s\tremaining: 9.18s\n",
            "834:\tlearn: 22.5500736\ttotal: 46.2s\tremaining: 9.12s\n",
            "835:\tlearn: 22.5500585\ttotal: 46.2s\tremaining: 9.06s\n",
            "836:\tlearn: 22.5500259\ttotal: 46.3s\tremaining: 9.01s\n",
            "837:\tlearn: 22.5499868\ttotal: 46.3s\tremaining: 8.95s\n",
            "838:\tlearn: 22.5498594\ttotal: 46.4s\tremaining: 8.9s\n",
            "839:\tlearn: 22.5498246\ttotal: 46.4s\tremaining: 8.84s\n",
            "840:\tlearn: 22.5497327\ttotal: 46.5s\tremaining: 8.78s\n",
            "841:\tlearn: 22.5496617\ttotal: 46.5s\tremaining: 8.72s\n",
            "842:\tlearn: 22.5496141\ttotal: 46.5s\tremaining: 8.67s\n",
            "843:\tlearn: 22.5495625\ttotal: 46.6s\tremaining: 8.61s\n",
            "844:\tlearn: 22.5493807\ttotal: 46.6s\tremaining: 8.55s\n",
            "845:\tlearn: 22.5492546\ttotal: 46.7s\tremaining: 8.5s\n",
            "846:\tlearn: 22.5491727\ttotal: 46.7s\tremaining: 8.44s\n",
            "847:\tlearn: 22.5490662\ttotal: 46.8s\tremaining: 8.38s\n",
            "848:\tlearn: 22.5489749\ttotal: 46.8s\tremaining: 8.33s\n",
            "849:\tlearn: 22.5488532\ttotal: 46.9s\tremaining: 8.27s\n",
            "850:\tlearn: 22.5488347\ttotal: 46.9s\tremaining: 8.21s\n",
            "851:\tlearn: 22.5486602\ttotal: 47s\tremaining: 8.16s\n",
            "852:\tlearn: 22.5485705\ttotal: 47s\tremaining: 8.1s\n",
            "853:\tlearn: 22.5485044\ttotal: 47.1s\tremaining: 8.04s\n",
            "854:\tlearn: 22.5484559\ttotal: 47.1s\tremaining: 7.99s\n",
            "855:\tlearn: 22.5484206\ttotal: 47.2s\tremaining: 7.93s\n",
            "856:\tlearn: 22.5483340\ttotal: 47.2s\tremaining: 7.88s\n",
            "857:\tlearn: 22.5483086\ttotal: 47.2s\tremaining: 7.82s\n",
            "858:\tlearn: 22.5482535\ttotal: 47.3s\tremaining: 7.76s\n",
            "859:\tlearn: 22.5481259\ttotal: 47.3s\tremaining: 7.71s\n",
            "860:\tlearn: 22.5480938\ttotal: 47.4s\tremaining: 7.65s\n",
            "861:\tlearn: 22.5480712\ttotal: 47.4s\tremaining: 7.59s\n",
            "862:\tlearn: 22.5480127\ttotal: 47.5s\tremaining: 7.54s\n",
            "863:\tlearn: 22.5479606\ttotal: 47.5s\tremaining: 7.48s\n",
            "864:\tlearn: 22.5479197\ttotal: 47.6s\tremaining: 7.42s\n",
            "865:\tlearn: 22.5478538\ttotal: 47.6s\tremaining: 7.37s\n",
            "866:\tlearn: 22.5477331\ttotal: 47.7s\tremaining: 7.31s\n",
            "867:\tlearn: 22.5476486\ttotal: 47.7s\tremaining: 7.25s\n",
            "868:\tlearn: 22.5475973\ttotal: 47.8s\tremaining: 7.2s\n",
            "869:\tlearn: 22.5475621\ttotal: 47.8s\tremaining: 7.14s\n",
            "870:\tlearn: 22.5474980\ttotal: 47.8s\tremaining: 7.09s\n",
            "871:\tlearn: 22.5473776\ttotal: 47.9s\tremaining: 7.03s\n",
            "872:\tlearn: 22.5472687\ttotal: 47.9s\tremaining: 6.97s\n",
            "873:\tlearn: 22.5471924\ttotal: 48s\tremaining: 6.92s\n",
            "874:\tlearn: 22.5471352\ttotal: 48.1s\tremaining: 6.87s\n",
            "875:\tlearn: 22.5470438\ttotal: 48.1s\tremaining: 6.81s\n",
            "876:\tlearn: 22.5469540\ttotal: 48.2s\tremaining: 6.75s\n",
            "877:\tlearn: 22.5469176\ttotal: 48.2s\tremaining: 6.7s\n",
            "878:\tlearn: 22.5468192\ttotal: 48.3s\tremaining: 6.64s\n",
            "879:\tlearn: 22.5467700\ttotal: 48.3s\tremaining: 6.59s\n",
            "880:\tlearn: 22.5467149\ttotal: 48.4s\tremaining: 6.53s\n",
            "881:\tlearn: 22.5466120\ttotal: 48.4s\tremaining: 6.48s\n",
            "882:\tlearn: 22.5465848\ttotal: 48.5s\tremaining: 6.42s\n",
            "883:\tlearn: 22.5465701\ttotal: 48.5s\tremaining: 6.37s\n",
            "884:\tlearn: 22.5465099\ttotal: 48.6s\tremaining: 6.31s\n",
            "885:\tlearn: 22.5464328\ttotal: 48.6s\tremaining: 6.26s\n",
            "886:\tlearn: 22.5463588\ttotal: 48.7s\tremaining: 6.2s\n",
            "887:\tlearn: 22.5462430\ttotal: 48.7s\tremaining: 6.14s\n",
            "888:\tlearn: 22.5461364\ttotal: 48.8s\tremaining: 6.09s\n",
            "889:\tlearn: 22.5460586\ttotal: 48.8s\tremaining: 6.04s\n",
            "890:\tlearn: 22.5460514\ttotal: 48.9s\tremaining: 5.98s\n",
            "891:\tlearn: 22.5459447\ttotal: 49s\tremaining: 5.93s\n",
            "892:\tlearn: 22.5458528\ttotal: 49s\tremaining: 5.87s\n",
            "893:\tlearn: 22.5457809\ttotal: 49.1s\tremaining: 5.82s\n",
            "894:\tlearn: 22.5457129\ttotal: 49.1s\tremaining: 5.76s\n",
            "895:\tlearn: 22.5456876\ttotal: 49.2s\tremaining: 5.71s\n",
            "896:\tlearn: 22.5456157\ttotal: 49.2s\tremaining: 5.65s\n",
            "897:\tlearn: 22.5455962\ttotal: 49.3s\tremaining: 5.6s\n",
            "898:\tlearn: 22.5455393\ttotal: 49.3s\tremaining: 5.54s\n",
            "899:\tlearn: 22.5455026\ttotal: 49.4s\tremaining: 5.49s\n",
            "900:\tlearn: 22.5454452\ttotal: 49.4s\tremaining: 5.43s\n",
            "901:\tlearn: 22.5453163\ttotal: 49.5s\tremaining: 5.38s\n",
            "902:\tlearn: 22.5453050\ttotal: 49.5s\tremaining: 5.32s\n",
            "903:\tlearn: 22.5452547\ttotal: 49.6s\tremaining: 5.26s\n",
            "904:\tlearn: 22.5451831\ttotal: 49.6s\tremaining: 5.21s\n",
            "905:\tlearn: 22.5451361\ttotal: 49.7s\tremaining: 5.15s\n",
            "906:\tlearn: 22.5450608\ttotal: 49.7s\tremaining: 5.1s\n",
            "907:\tlearn: 22.5449551\ttotal: 49.8s\tremaining: 5.04s\n",
            "908:\tlearn: 22.5448890\ttotal: 49.8s\tremaining: 4.99s\n",
            "909:\tlearn: 22.5448214\ttotal: 49.9s\tremaining: 4.93s\n",
            "910:\tlearn: 22.5447644\ttotal: 49.9s\tremaining: 4.88s\n",
            "911:\tlearn: 22.5447531\ttotal: 50s\tremaining: 4.82s\n",
            "912:\tlearn: 22.5446648\ttotal: 50s\tremaining: 4.77s\n",
            "913:\tlearn: 22.5445809\ttotal: 50.1s\tremaining: 4.71s\n",
            "914:\tlearn: 22.5445283\ttotal: 50.1s\tremaining: 4.66s\n",
            "915:\tlearn: 22.5444616\ttotal: 50.2s\tremaining: 4.6s\n",
            "916:\tlearn: 22.5443747\ttotal: 50.2s\tremaining: 4.55s\n",
            "917:\tlearn: 22.5443241\ttotal: 50.3s\tremaining: 4.49s\n",
            "918:\tlearn: 22.5442714\ttotal: 50.3s\tremaining: 4.44s\n",
            "919:\tlearn: 22.5442429\ttotal: 50.4s\tremaining: 4.38s\n",
            "920:\tlearn: 22.5442215\ttotal: 50.4s\tremaining: 4.33s\n",
            "921:\tlearn: 22.5441895\ttotal: 50.5s\tremaining: 4.27s\n",
            "922:\tlearn: 22.5441279\ttotal: 50.5s\tremaining: 4.21s\n",
            "923:\tlearn: 22.5440645\ttotal: 50.6s\tremaining: 4.16s\n",
            "924:\tlearn: 22.5439975\ttotal: 50.6s\tremaining: 4.1s\n",
            "925:\tlearn: 22.5439080\ttotal: 50.7s\tremaining: 4.05s\n",
            "926:\tlearn: 22.5438486\ttotal: 50.7s\tremaining: 3.99s\n",
            "927:\tlearn: 22.5438025\ttotal: 50.8s\tremaining: 3.94s\n",
            "928:\tlearn: 22.5437106\ttotal: 50.8s\tremaining: 3.88s\n",
            "929:\tlearn: 22.5436631\ttotal: 50.9s\tremaining: 3.83s\n",
            "930:\tlearn: 22.5435490\ttotal: 50.9s\tremaining: 3.77s\n",
            "931:\tlearn: 22.5435360\ttotal: 51s\tremaining: 3.72s\n",
            "932:\tlearn: 22.5434362\ttotal: 51s\tremaining: 3.66s\n",
            "933:\tlearn: 22.5434297\ttotal: 51.1s\tremaining: 3.61s\n",
            "934:\tlearn: 22.5433906\ttotal: 51.1s\tremaining: 3.55s\n",
            "935:\tlearn: 22.5433772\ttotal: 51.1s\tremaining: 3.5s\n",
            "936:\tlearn: 22.5433330\ttotal: 51.2s\tremaining: 3.44s\n",
            "937:\tlearn: 22.5433091\ttotal: 51.2s\tremaining: 3.39s\n",
            "938:\tlearn: 22.5432974\ttotal: 51.3s\tremaining: 3.33s\n",
            "939:\tlearn: 22.5432777\ttotal: 51.3s\tremaining: 3.28s\n",
            "940:\tlearn: 22.5432594\ttotal: 51.4s\tremaining: 3.22s\n",
            "941:\tlearn: 22.5432538\ttotal: 51.4s\tremaining: 3.17s\n",
            "942:\tlearn: 22.5432028\ttotal: 51.5s\tremaining: 3.11s\n",
            "943:\tlearn: 22.5431435\ttotal: 51.5s\tremaining: 3.06s\n",
            "944:\tlearn: 22.5431011\ttotal: 51.6s\tremaining: 3s\n",
            "945:\tlearn: 22.5430322\ttotal: 51.6s\tremaining: 2.94s\n",
            "946:\tlearn: 22.5430230\ttotal: 51.7s\tremaining: 2.89s\n",
            "947:\tlearn: 22.5430054\ttotal: 51.7s\tremaining: 2.83s\n",
            "948:\tlearn: 22.5429935\ttotal: 51.7s\tremaining: 2.78s\n",
            "949:\tlearn: 22.5429752\ttotal: 51.8s\tremaining: 2.73s\n",
            "950:\tlearn: 22.5429583\ttotal: 51.8s\tremaining: 2.67s\n",
            "951:\tlearn: 22.5428831\ttotal: 51.9s\tremaining: 2.62s\n",
            "952:\tlearn: 22.5428406\ttotal: 51.9s\tremaining: 2.56s\n",
            "953:\tlearn: 22.5428203\ttotal: 52s\tremaining: 2.51s\n",
            "954:\tlearn: 22.5427774\ttotal: 52s\tremaining: 2.45s\n",
            "955:\tlearn: 22.5427025\ttotal: 52.1s\tremaining: 2.4s\n",
            "956:\tlearn: 22.5426500\ttotal: 52.1s\tremaining: 2.34s\n",
            "957:\tlearn: 22.5426199\ttotal: 52.2s\tremaining: 2.29s\n",
            "958:\tlearn: 22.5425397\ttotal: 52.2s\tremaining: 2.23s\n",
            "959:\tlearn: 22.5424546\ttotal: 52.3s\tremaining: 2.18s\n",
            "960:\tlearn: 22.5424128\ttotal: 52.3s\tremaining: 2.12s\n",
            "961:\tlearn: 22.5423368\ttotal: 52.4s\tremaining: 2.07s\n",
            "962:\tlearn: 22.5423175\ttotal: 52.4s\tremaining: 2.01s\n",
            "963:\tlearn: 22.5423123\ttotal: 52.5s\tremaining: 1.96s\n",
            "964:\tlearn: 22.5423038\ttotal: 52.5s\tremaining: 1.9s\n",
            "965:\tlearn: 22.5422810\ttotal: 52.6s\tremaining: 1.85s\n",
            "966:\tlearn: 22.5421996\ttotal: 52.6s\tremaining: 1.8s\n",
            "967:\tlearn: 22.5421251\ttotal: 52.7s\tremaining: 1.74s\n",
            "968:\tlearn: 22.5420695\ttotal: 52.8s\tremaining: 1.69s\n",
            "969:\tlearn: 22.5420634\ttotal: 52.9s\tremaining: 1.64s\n",
            "970:\tlearn: 22.5420247\ttotal: 53s\tremaining: 1.58s\n",
            "971:\tlearn: 22.5419866\ttotal: 53.1s\tremaining: 1.53s\n",
            "972:\tlearn: 22.5419586\ttotal: 53.2s\tremaining: 1.48s\n",
            "973:\tlearn: 22.5419367\ttotal: 53.2s\tremaining: 1.42s\n",
            "974:\tlearn: 22.5418646\ttotal: 53.3s\tremaining: 1.37s\n",
            "975:\tlearn: 22.5418105\ttotal: 53.4s\tremaining: 1.31s\n",
            "976:\tlearn: 22.5417955\ttotal: 53.5s\tremaining: 1.26s\n",
            "977:\tlearn: 22.5417782\ttotal: 53.6s\tremaining: 1.21s\n",
            "978:\tlearn: 22.5417013\ttotal: 53.7s\tremaining: 1.15s\n",
            "979:\tlearn: 22.5416788\ttotal: 53.8s\tremaining: 1.1s\n",
            "980:\tlearn: 22.5416018\ttotal: 53.9s\tremaining: 1.04s\n",
            "981:\tlearn: 22.5415033\ttotal: 54s\tremaining: 989ms\n",
            "982:\tlearn: 22.5414570\ttotal: 54.1s\tremaining: 935ms\n",
            "983:\tlearn: 22.5413769\ttotal: 54.2s\tremaining: 881ms\n",
            "984:\tlearn: 22.5413191\ttotal: 54.2s\tremaining: 826ms\n",
            "985:\tlearn: 22.5412723\ttotal: 54.3s\tremaining: 771ms\n",
            "986:\tlearn: 22.5412438\ttotal: 54.4s\tremaining: 717ms\n",
            "987:\tlearn: 22.5412209\ttotal: 54.5s\tremaining: 662ms\n",
            "988:\tlearn: 22.5411875\ttotal: 54.6s\tremaining: 607ms\n",
            "989:\tlearn: 22.5411656\ttotal: 54.7s\tremaining: 552ms\n",
            "990:\tlearn: 22.5411027\ttotal: 54.8s\tremaining: 497ms\n",
            "991:\tlearn: 22.5410972\ttotal: 54.9s\tremaining: 442ms\n",
            "992:\tlearn: 22.5410422\ttotal: 54.9s\tremaining: 387ms\n",
            "993:\tlearn: 22.5409989\ttotal: 55s\tremaining: 332ms\n",
            "994:\tlearn: 22.5409542\ttotal: 55.1s\tremaining: 277ms\n",
            "995:\tlearn: 22.5409385\ttotal: 55.2s\tremaining: 222ms\n",
            "996:\tlearn: 22.5408856\ttotal: 55.3s\tremaining: 166ms\n",
            "997:\tlearn: 22.5408452\ttotal: 55.4s\tremaining: 111ms\n",
            "998:\tlearn: 22.5407810\ttotal: 55.4s\tremaining: 55.5ms\n",
            "999:\tlearn: 22.5407428\ttotal: 55.5s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the feature importances for each algorithm\n",
        "rf_feature_importances = rf.feature_importances_\n",
        "lr_feature_importances = lr.coef_\n",
        "dt_feature_importances = dt.feature_importances_\n",
        "svm_feature_importances = None\n",
        "if svm.kernel == 'linear':\n",
        "    svm_feature_importances = svm.coef_\n",
        "else:\n",
        "    svm_feature_importances = svm.feature_importances_\n",
        "xgb_feature_importances = xgb.feature_importances_\n",
        "lgbm_feature_importances = lgbm.feature_importances_\n",
        "cat_feature_importances = cat.feature_importances_\n",
        "mlp_feature_importances = mlp.coefs_\n",
        "gb_feature_importances = gb.feature_importances_\n",
        "et_feature_importances = et.feature_importances_"
      ],
      "metadata": {
        "id": "7SI3wRh2J1Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the feature importances in a dataframe for comparison\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Algorithm': ['Random Forest', 'Linear Regression', 'Decision Tree', 'Support Vector Machine', 'XGBoost', 'LightGBM', 'CatBoost', 'MLP', 'Gradient Boosting', 'Extra Trees'],\n",
        "    'Feature Importances': [rf_feature_importances, lr_feature_importances, dt_feature_importances, svm_feature_importances, xgb_feature_importances, lgbm_feature_importances,\n",
        "                            cat_feature_importances, mlp_feature_importances, gb_feature_importances, et_feature_importances]\n",
        "})\n",
        "\n",
        "# Save feature importances to a CSV file\n",
        "feature_importances_df.to_csv('feature_importances.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ske4Hn96MJlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ],
      "metadata": {
        "id": "UYIsowTiT89t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:-1]\n",
        "y = data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "WzPb2dMSUCmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "#for i, importance in enumerate(importances):\n",
        "    #print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('RF_feature_importances.csv', index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "KrUvfepIXIyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "svr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.abs(svr.coef_[0])\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = svr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics =\n",
        "\n"
      ],
      "metadata": {
        "id": "xvBMOlbo9xt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)"
      ],
      "metadata": {
        "id": "gJ-R4Ge2YHZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=True)"
      ],
      "metadata": {
        "id": "kQ3VIvM7YIx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = dt.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = dt.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('decision_tree_metrics.csv', index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cJjPX__fLm9",
        "outputId": "0308212b-462b-4b23-97e5-4be4efa52ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1: 0.000\n",
            "Feature 2: 0.000\n",
            "Feature 3: 0.000\n",
            "Feature 4: 0.000\n",
            "Feature 5: 0.000\n",
            "Feature 6: 0.000\n",
            "Feature 7: 0.000\n",
            "Feature 8: 0.000\n",
            "Feature 9: 0.000\n",
            "Feature 10: 0.000\n",
            "Feature 11: 0.001\n",
            "Feature 12: 0.012\n",
            "Feature 13: 0.000\n",
            "Feature 14: 0.000\n",
            "Feature 15: 0.000\n",
            "Feature 16: 0.000\n",
            "Feature 17: 0.000\n",
            "Feature 18: 0.000\n",
            "Feature 19: 0.000\n",
            "Feature 20: 0.000\n",
            "Feature 21: 0.000\n",
            "Feature 22: 0.000\n",
            "Feature 23: 0.000\n",
            "Feature 24: 0.001\n",
            "Feature 25: 0.000\n",
            "Feature 26: 0.000\n",
            "Feature 27: 0.000\n",
            "Feature 28: 0.000\n",
            "Feature 29: 0.000\n",
            "Feature 30: 0.000\n",
            "Feature 31: 0.000\n",
            "Feature 32: 0.000\n",
            "Feature 33: 0.000\n",
            "Feature 34: 0.000\n",
            "Feature 35: 0.000\n",
            "Feature 36: 0.000\n",
            "Feature 37: 0.000\n",
            "Feature 38: 0.000\n",
            "Feature 39: 0.000\n",
            "Feature 40: 0.000\n",
            "Feature 41: 0.000\n",
            "Feature 42: 0.000\n",
            "Feature 43: 0.000\n",
            "Feature 44: 0.000\n",
            "Feature 45: 0.165\n",
            "Feature 46: 0.000\n",
            "Feature 47: 0.000\n",
            "Feature 48: 0.001\n",
            "Feature 49: 0.000\n",
            "Feature 50: 0.000\n",
            "Feature 51: 0.000\n",
            "Feature 52: 0.001\n",
            "Feature 53: 0.000\n",
            "Feature 54: 0.000\n",
            "Feature 55: 0.000\n",
            "Feature 56: 0.000\n",
            "Feature 57: 0.000\n",
            "Feature 58: 0.000\n",
            "Feature 59: 0.000\n",
            "Feature 60: 0.000\n",
            "Feature 61: 0.000\n",
            "Feature 62: 0.000\n",
            "Feature 63: 0.000\n",
            "Feature 64: 0.000\n",
            "Feature 65: 0.000\n",
            "Feature 66: 0.000\n",
            "Feature 67: 0.000\n",
            "Feature 68: 0.000\n",
            "Feature 69: 0.000\n",
            "Feature 70: 0.000\n",
            "Feature 71: 0.000\n",
            "Feature 72: 0.000\n",
            "Feature 73: 0.000\n",
            "Feature 74: 0.000\n",
            "Feature 75: 0.000\n",
            "Feature 76: 0.001\n",
            "Feature 77: 0.000\n",
            "Feature 78: 0.000\n",
            "Feature 79: 0.000\n",
            "Feature 80: 0.000\n",
            "Feature 81: 0.000\n",
            "Feature 82: 0.000\n",
            "Feature 83: 0.000\n",
            "Feature 84: 0.000\n",
            "Feature 85: 0.000\n",
            "Feature 86: 0.000\n",
            "Feature 87: 0.000\n",
            "Feature 88: 0.000\n",
            "Feature 89: 0.000\n",
            "Feature 90: 0.000\n",
            "Feature 91: 0.000\n",
            "Feature 92: 0.000\n",
            "Feature 93: 0.000\n",
            "Feature 94: 0.000\n",
            "Feature 95: 0.000\n",
            "Feature 96: 0.000\n",
            "Feature 97: 0.116\n",
            "Feature 98: 0.000\n",
            "Feature 99: 0.000\n",
            "Feature 100: 0.000\n",
            "Feature 101: 0.000\n",
            "Feature 102: 0.000\n",
            "Feature 103: 0.000\n",
            "Feature 104: 0.000\n",
            "Feature 105: 0.000\n",
            "Feature 106: 0.000\n",
            "Feature 107: 0.000\n",
            "Feature 108: 0.000\n",
            "Feature 109: 0.000\n",
            "Feature 110: 0.000\n",
            "Feature 111: 0.000\n",
            "Feature 112: 0.000\n",
            "Feature 113: 0.002\n",
            "Feature 114: 0.000\n",
            "Feature 115: 0.000\n",
            "Feature 116: 0.000\n",
            "Feature 117: 0.000\n",
            "Feature 118: 0.000\n",
            "Feature 119: 0.000\n",
            "Feature 120: 0.000\n",
            "Feature 121: 0.000\n",
            "Feature 122: 0.000\n",
            "Feature 123: 0.000\n",
            "Feature 124: 0.000\n",
            "Feature 125: 0.000\n",
            "Feature 126: 0.000\n",
            "Feature 127: 0.000\n",
            "Feature 128: 0.006\n",
            "Feature 129: 0.000\n",
            "Feature 130: 0.000\n",
            "Feature 131: 0.000\n",
            "Feature 132: 0.000\n",
            "Feature 133: 0.001\n",
            "Feature 134: 0.001\n",
            "Feature 135: 0.009\n",
            "Feature 136: 0.000\n",
            "Feature 137: 0.000\n",
            "Feature 138: 0.000\n",
            "Feature 139: 0.000\n",
            "Feature 140: 0.000\n",
            "Feature 141: 0.000\n",
            "Feature 142: 0.000\n",
            "Feature 143: 0.000\n",
            "Feature 144: 0.018\n",
            "Feature 145: 0.000\n",
            "Feature 146: 0.000\n",
            "Feature 147: 0.000\n",
            "Feature 148: 0.000\n",
            "Feature 149: 0.000\n",
            "Feature 150: 0.000\n",
            "Feature 151: 0.000\n",
            "Feature 152: 0.000\n",
            "Feature 153: 0.000\n",
            "Feature 154: 0.000\n",
            "Feature 155: 0.000\n",
            "Feature 156: 0.000\n",
            "Feature 157: 0.000\n",
            "Feature 158: 0.000\n",
            "Feature 159: 0.000\n",
            "Feature 160: 0.000\n",
            "Feature 161: 0.000\n",
            "Feature 162: 0.000\n",
            "Feature 163: 0.000\n",
            "Feature 164: 0.000\n",
            "Feature 165: 0.000\n",
            "Feature 166: 0.000\n",
            "Feature 167: 0.000\n",
            "Feature 168: 0.000\n",
            "Feature 169: 0.000\n",
            "Feature 170: 0.000\n",
            "Feature 171: 0.000\n",
            "Feature 172: 0.000\n",
            "Feature 173: 0.000\n",
            "Feature 174: 0.000\n",
            "Feature 175: 0.000\n",
            "Feature 176: 0.000\n",
            "Feature 177: 0.000\n",
            "Feature 178: 0.554\n",
            "Feature 179: 0.000\n",
            "Feature 180: 0.000\n",
            "Feature 181: 0.000\n",
            "Feature 182: 0.000\n",
            "Feature 183: 0.000\n",
            "Feature 184: 0.000\n",
            "Feature 185: 0.000\n",
            "Feature 186: 0.000\n",
            "Feature 187: 0.100\n",
            "Feature 188: 0.000\n",
            "Feature 189: 0.002\n",
            "Feature 190: 0.005\n",
            "Feature 191: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "svr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.abs(svr.coef_[0])\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = svr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('svr_metrics.csv', index=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynKqVIYb-JSs",
        "outputId": "6cf3fec2-0e30-464d-f652-8cda56a113c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1: 0.145\n",
            "Feature 2: 0.126\n",
            "Feature 3: 0.167\n",
            "Feature 4: 0.153\n",
            "Feature 5: 0.166\n",
            "Feature 6: 0.207\n",
            "Feature 7: 0.167\n",
            "Feature 8: 0.133\n",
            "Feature 9: 0.143\n",
            "Feature 10: 0.163\n",
            "Feature 11: 0.184\n",
            "Feature 12: 0.142\n",
            "Feature 13: 0.165\n",
            "Feature 14: 0.197\n",
            "Feature 15: 0.225\n",
            "Feature 16: 0.210\n",
            "Feature 17: 0.222\n",
            "Feature 18: 0.245\n",
            "Feature 19: 0.177\n",
            "Feature 20: 0.171\n",
            "Feature 21: 0.169\n",
            "Feature 22: 0.173\n",
            "Feature 23: 0.158\n",
            "Feature 24: 0.165\n",
            "Feature 25: 0.126\n",
            "Feature 26: 0.083\n",
            "Feature 27: 0.096\n",
            "Feature 28: 0.115\n",
            "Feature 29: 0.022\n",
            "Feature 30: 0.136\n",
            "Feature 31: 0.284\n",
            "Feature 32: 0.275\n",
            "Feature 33: 0.384\n",
            "Feature 34: 0.304\n",
            "Feature 35: 0.339\n",
            "Feature 36: 0.328\n",
            "Feature 37: 0.358\n",
            "Feature 38: 0.417\n",
            "Feature 39: 0.449\n",
            "Feature 40: 0.431\n",
            "Feature 41: 0.446\n",
            "Feature 42: 0.523\n",
            "Feature 43: 0.498\n",
            "Feature 44: 0.484\n",
            "Feature 45: 0.517\n",
            "Feature 46: 0.547\n",
            "Feature 47: 0.526\n",
            "Feature 48: 0.512\n",
            "Feature 49: 0.607\n",
            "Feature 50: 0.606\n",
            "Feature 51: 0.453\n",
            "Feature 52: 0.719\n",
            "Feature 53: 0.555\n",
            "Feature 54: 0.569\n",
            "Feature 55: 0.462\n",
            "Feature 56: 0.541\n",
            "Feature 57: 0.467\n",
            "Feature 58: 0.520\n",
            "Feature 59: 0.422\n",
            "Feature 60: 0.543\n",
            "Feature 61: 0.472\n",
            "Feature 62: 0.483\n",
            "Feature 63: 0.445\n",
            "Feature 64: 0.455\n",
            "Feature 65: 0.457\n",
            "Feature 66: 0.452\n",
            "Feature 67: 0.419\n",
            "Feature 68: 0.435\n",
            "Feature 69: 0.470\n",
            "Feature 70: 0.499\n",
            "Feature 71: 0.479\n",
            "Feature 72: 0.571\n",
            "Feature 73: 0.403\n",
            "Feature 74: 0.662\n",
            "Feature 75: 0.709\n",
            "Feature 76: 0.532\n",
            "Feature 77: 0.588\n",
            "Feature 78: 0.520\n",
            "Feature 79: 0.572\n",
            "Feature 80: 0.501\n",
            "Feature 81: 0.547\n",
            "Feature 82: 0.564\n",
            "Feature 83: 0.508\n",
            "Feature 84: 0.502\n",
            "Feature 85: 0.484\n",
            "Feature 86: 0.559\n",
            "Feature 87: 0.591\n",
            "Feature 88: 0.497\n",
            "Feature 89: 0.527\n",
            "Feature 90: 0.475\n",
            "Feature 91: 0.473\n",
            "Feature 92: 0.420\n",
            "Feature 93: 0.446\n",
            "Feature 94: 0.218\n",
            "Feature 95: 0.371\n",
            "Feature 96: 0.194\n",
            "Feature 97: 0.594\n",
            "Feature 98: 0.444\n",
            "Feature 99: 0.375\n",
            "Feature 100: 0.329\n",
            "Feature 101: 0.318\n",
            "Feature 102: 0.292\n",
            "Feature 103: 0.298\n",
            "Feature 104: 0.298\n",
            "Feature 105: 0.258\n",
            "Feature 106: 0.300\n",
            "Feature 107: 0.345\n",
            "Feature 108: 0.299\n",
            "Feature 109: 0.301\n",
            "Feature 110: 0.356\n",
            "Feature 111: 0.325\n",
            "Feature 112: 0.349\n",
            "Feature 113: 0.301\n",
            "Feature 114: 0.357\n",
            "Feature 115: 0.368\n",
            "Feature 116: 0.303\n",
            "Feature 117: 0.377\n",
            "Feature 118: 0.296\n",
            "Feature 119: 0.368\n",
            "Feature 120: 0.303\n",
            "Feature 121: 0.278\n",
            "Feature 122: 0.340\n",
            "Feature 123: 0.315\n",
            "Feature 124: 0.332\n",
            "Feature 125: 0.413\n",
            "Feature 126: 0.411\n",
            "Feature 127: 0.358\n",
            "Feature 128: 0.153\n",
            "Feature 129: 0.406\n",
            "Feature 130: 0.236\n",
            "Feature 131: 0.310\n",
            "Feature 132: 0.132\n",
            "Feature 133: 0.306\n",
            "Feature 134: 0.272\n",
            "Feature 135: 0.256\n",
            "Feature 136: 0.155\n",
            "Feature 137: 0.270\n",
            "Feature 138: 0.194\n",
            "Feature 139: 0.129\n",
            "Feature 140: 0.074\n",
            "Feature 141: 0.262\n",
            "Feature 142: 0.235\n",
            "Feature 143: 0.282\n",
            "Feature 144: 0.336\n",
            "Feature 145: 0.312\n",
            "Feature 146: 0.201\n",
            "Feature 147: 0.147\n",
            "Feature 148: 0.140\n",
            "Feature 149: 0.191\n",
            "Feature 150: 0.280\n",
            "Feature 151: 0.199\n",
            "Feature 152: 0.173\n",
            "Feature 153: 0.235\n",
            "Feature 154: 0.336\n",
            "Feature 155: 0.154\n",
            "Feature 156: 0.093\n",
            "Feature 157: 0.223\n",
            "Feature 158: 0.339\n",
            "Feature 159: 0.165\n",
            "Feature 160: 0.144\n",
            "Feature 161: 0.336\n",
            "Feature 162: 0.289\n",
            "Feature 163: 0.232\n",
            "Feature 164: 0.088\n",
            "Feature 165: 0.254\n",
            "Feature 166: 0.183\n",
            "Feature 167: 0.290\n",
            "Feature 168: 0.396\n",
            "Feature 169: 0.168\n",
            "Feature 170: 0.116\n",
            "Feature 171: 0.149\n",
            "Feature 172: 0.180\n",
            "Feature 173: 0.110\n",
            "Feature 174: 0.164\n",
            "Feature 175: 0.182\n",
            "Feature 176: 0.116\n",
            "Feature 177: 0.042\n",
            "Feature 178: 0.100\n",
            "Feature 179: 0.149\n",
            "Feature 180: 0.162\n",
            "Feature 181: 0.254\n",
            "Feature 182: 0.111\n",
            "Feature 183: 0.101\n",
            "Feature 184: 0.072\n",
            "Feature 185: 0.044\n",
            "Feature 186: 0.147\n",
            "Feature 187: 0.036\n",
            "Feature 188: 0.099\n",
            "Feature 189: 0.020\n",
            "Feature 190: 0.065\n",
            "Feature 191: 0.256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a XGBRegressor model\n",
        "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "xgb.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = xgb.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('XGB Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = xgb.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('xgb_metrics.csv', index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqS59_p9_VSS",
        "outputId": "0d0c7ea9-39db-4843-fa5f-3538b567912f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Feature 1: 0.018\n",
            "XGB Feature 2: 0.000\n",
            "XGB Feature 3: 0.005\n",
            "XGB Feature 4: 0.000\n",
            "XGB Feature 5: 0.000\n",
            "XGB Feature 6: 0.000\n",
            "XGB Feature 7: 0.000\n",
            "XGB Feature 8: 0.000\n",
            "XGB Feature 9: 0.000\n",
            "XGB Feature 10: 0.000\n",
            "XGB Feature 11: 0.000\n",
            "XGB Feature 12: 0.000\n",
            "XGB Feature 13: 0.000\n",
            "XGB Feature 14: 0.000\n",
            "XGB Feature 15: 0.000\n",
            "XGB Feature 16: 0.000\n",
            "XGB Feature 17: 0.000\n",
            "XGB Feature 18: 0.000\n",
            "XGB Feature 19: 0.002\n",
            "XGB Feature 20: 0.000\n",
            "XGB Feature 21: 0.000\n",
            "XGB Feature 22: 0.000\n",
            "XGB Feature 23: 0.000\n",
            "XGB Feature 24: 0.000\n",
            "XGB Feature 25: 0.000\n",
            "XGB Feature 26: 0.000\n",
            "XGB Feature 27: 0.000\n",
            "XGB Feature 28: 0.000\n",
            "XGB Feature 29: 0.001\n",
            "XGB Feature 30: 0.000\n",
            "XGB Feature 31: 0.000\n",
            "XGB Feature 32: 0.000\n",
            "XGB Feature 33: 0.000\n",
            "XGB Feature 34: 0.000\n",
            "XGB Feature 35: 0.002\n",
            "XGB Feature 36: 0.000\n",
            "XGB Feature 37: 0.002\n",
            "XGB Feature 38: 0.000\n",
            "XGB Feature 39: 0.002\n",
            "XGB Feature 40: 0.000\n",
            "XGB Feature 41: 0.000\n",
            "XGB Feature 42: 0.000\n",
            "XGB Feature 43: 0.000\n",
            "XGB Feature 44: 0.005\n",
            "XGB Feature 45: 0.001\n",
            "XGB Feature 46: 0.000\n",
            "XGB Feature 47: 0.000\n",
            "XGB Feature 48: 0.000\n",
            "XGB Feature 49: 0.000\n",
            "XGB Feature 50: 0.000\n",
            "XGB Feature 51: 0.000\n",
            "XGB Feature 52: 0.205\n",
            "XGB Feature 53: 0.000\n",
            "XGB Feature 54: 0.001\n",
            "XGB Feature 55: 0.009\n",
            "XGB Feature 56: 0.000\n",
            "XGB Feature 57: 0.001\n",
            "XGB Feature 58: 0.000\n",
            "XGB Feature 59: 0.000\n",
            "XGB Feature 60: 0.000\n",
            "XGB Feature 61: 0.000\n",
            "XGB Feature 62: 0.000\n",
            "XGB Feature 63: 0.000\n",
            "XGB Feature 64: 0.000\n",
            "XGB Feature 65: 0.000\n",
            "XGB Feature 66: 0.000\n",
            "XGB Feature 67: 0.000\n",
            "XGB Feature 68: 0.000\n",
            "XGB Feature 69: 0.000\n",
            "XGB Feature 70: 0.000\n",
            "XGB Feature 71: 0.000\n",
            "XGB Feature 72: 0.038\n",
            "XGB Feature 73: 0.000\n",
            "XGB Feature 74: 0.000\n",
            "XGB Feature 75: 0.002\n",
            "XGB Feature 76: 0.000\n",
            "XGB Feature 77: 0.000\n",
            "XGB Feature 78: 0.000\n",
            "XGB Feature 79: 0.000\n",
            "XGB Feature 80: 0.000\n",
            "XGB Feature 81: 0.000\n",
            "XGB Feature 82: 0.004\n",
            "XGB Feature 83: 0.000\n",
            "XGB Feature 84: 0.000\n",
            "XGB Feature 85: 0.000\n",
            "XGB Feature 86: 0.000\n",
            "XGB Feature 87: 0.000\n",
            "XGB Feature 88: 0.000\n",
            "XGB Feature 89: 0.000\n",
            "XGB Feature 90: 0.000\n",
            "XGB Feature 91: 0.000\n",
            "XGB Feature 92: 0.001\n",
            "XGB Feature 93: 0.001\n",
            "XGB Feature 94: 0.000\n",
            "XGB Feature 95: 0.000\n",
            "XGB Feature 96: 0.000\n",
            "XGB Feature 97: 0.001\n",
            "XGB Feature 98: 0.000\n",
            "XGB Feature 99: 0.000\n",
            "XGB Feature 100: 0.000\n",
            "XGB Feature 101: 0.000\n",
            "XGB Feature 102: 0.000\n",
            "XGB Feature 103: 0.000\n",
            "XGB Feature 104: 0.000\n",
            "XGB Feature 105: 0.000\n",
            "XGB Feature 106: 0.000\n",
            "XGB Feature 107: 0.000\n",
            "XGB Feature 108: 0.000\n",
            "XGB Feature 109: 0.000\n",
            "XGB Feature 110: 0.000\n",
            "XGB Feature 111: 0.000\n",
            "XGB Feature 112: 0.000\n",
            "XGB Feature 113: 0.000\n",
            "XGB Feature 114: 0.002\n",
            "XGB Feature 115: 0.000\n",
            "XGB Feature 116: 0.000\n",
            "XGB Feature 117: 0.000\n",
            "XGB Feature 118: 0.000\n",
            "XGB Feature 119: 0.000\n",
            "XGB Feature 120: 0.000\n",
            "XGB Feature 121: 0.000\n",
            "XGB Feature 122: 0.001\n",
            "XGB Feature 123: 0.000\n",
            "XGB Feature 124: 0.000\n",
            "XGB Feature 125: 0.000\n",
            "XGB Feature 126: 0.001\n",
            "XGB Feature 127: 0.000\n",
            "XGB Feature 128: 0.000\n",
            "XGB Feature 129: 0.000\n",
            "XGB Feature 130: 0.000\n",
            "XGB Feature 131: 0.000\n",
            "XGB Feature 132: 0.000\n",
            "XGB Feature 133: 0.645\n",
            "XGB Feature 134: 0.000\n",
            "XGB Feature 135: 0.007\n",
            "XGB Feature 136: 0.000\n",
            "XGB Feature 137: 0.000\n",
            "XGB Feature 138: 0.000\n",
            "XGB Feature 139: 0.000\n",
            "XGB Feature 140: 0.000\n",
            "XGB Feature 141: 0.000\n",
            "XGB Feature 142: 0.000\n",
            "XGB Feature 143: 0.000\n",
            "XGB Feature 144: 0.005\n",
            "XGB Feature 145: 0.000\n",
            "XGB Feature 146: 0.000\n",
            "XGB Feature 147: 0.000\n",
            "XGB Feature 148: 0.000\n",
            "XGB Feature 149: 0.000\n",
            "XGB Feature 150: 0.001\n",
            "XGB Feature 151: 0.000\n",
            "XGB Feature 152: 0.000\n",
            "XGB Feature 153: 0.000\n",
            "XGB Feature 154: 0.000\n",
            "XGB Feature 155: 0.000\n",
            "XGB Feature 156: 0.001\n",
            "XGB Feature 157: 0.000\n",
            "XGB Feature 158: 0.000\n",
            "XGB Feature 159: 0.001\n",
            "XGB Feature 160: 0.000\n",
            "XGB Feature 161: 0.000\n",
            "XGB Feature 162: 0.000\n",
            "XGB Feature 163: 0.000\n",
            "XGB Feature 164: 0.000\n",
            "XGB Feature 165: 0.000\n",
            "XGB Feature 166: 0.000\n",
            "XGB Feature 167: 0.000\n",
            "XGB Feature 168: 0.000\n",
            "XGB Feature 169: 0.000\n",
            "XGB Feature 170: 0.000\n",
            "XGB Feature 171: 0.000\n",
            "XGB Feature 172: 0.000\n",
            "XGB Feature 173: 0.000\n",
            "XGB Feature 174: 0.001\n",
            "XGB Feature 175: 0.000\n",
            "XGB Feature 176: 0.000\n",
            "XGB Feature 177: 0.000\n",
            "XGB Feature 178: 0.000\n",
            "XGB Feature 179: 0.000\n",
            "XGB Feature 180: 0.000\n",
            "XGB Feature 181: 0.020\n",
            "XGB Feature 182: 0.000\n",
            "XGB Feature 183: 0.000\n",
            "XGB Feature 184: 0.000\n",
            "XGB Feature 185: 0.000\n",
            "XGB Feature 186: 0.000\n",
            "XGB Feature 187: 0.000\n",
            "XGB Feature 188: 0.000\n",
            "XGB Feature 189: 0.000\n",
            "XGB Feature 190: 0.005\n",
            "XGB Feature 191: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LGBMRegressor model\n",
        "lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "lgbm.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = lgbm.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('LGBM Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = lgbm.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('lgbm_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "bhtWBghWWtRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb = CatBoostRegressor(iterations=100, learning_rate=0.1, random_seed=42)\n",
        "cb.fit(X, y, verbose=False)\n",
        "importances = cb.feature_importances_\n",
        "#for i, importance in enumerate(importances):\n",
        " #print('Feature %d: %.3f' % (i+1, importance))\n",
        "# Calculate performance metrics\n",
        "y_pred = cb.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('catboost_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "8GmxiTW_ZuXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "gbr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = gbr.feature_importances_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = gbr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('gbr_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "k6-Ky_J3lc62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an extra trees regressor model\n",
        "etr = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "etr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = etr.feature_importances_\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = etr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('etr_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "erEG5KCGmD0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "metadata": {
        "id": "cvZH2o_knM65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an extra trees regressor model\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.zeros(X.shape[1])\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = lgbm.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('knn_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "kxN0H4Nun_YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "zPEYZ3NMqEKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PCA to reduce the number of features\n",
        "pca = PCA(n_components=10)\n",
        "X_pca = pca.fit_transform(X)\n",
        "dt.fit(X_pca, y)\n",
        "importances_pca = dt.feature_importances_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = dt.predict(X_pca)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances_pca, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('pca_dt_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "557z_T98qFOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Create RFE model and select top n features\n",
        "n = 10 # choose the number of top features to select\n",
        "rfe = RFE(estimator=DecisionTreeRegressor(random_state=42), n_features_to_select=n)\n",
        "rfe.fit(X, y)\n",
        "# Get ranking of input features based on RFE\n",
        "rfe_ranking = rfe.ranking_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rfe.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': rfe_ranking, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('recursive_feature_elimination_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "kkqE6ADvdLV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Calculate permutation importance\n",
        "permutation_importances = permutation_importance(rf, X, y, random_state=42)\n",
        "importances = permutation_importances.importances_mean\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('permutation_importance_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "FlHqaT0KfwiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "sq5ZfWaWoAgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en = ElasticNet(random_state=42)"
      ],
      "metadata": {
        "id": "-o12daXVoDzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en.fit(X, y)\n",
        "importances = np.abs(en.coef_)\n",
        "#importances = coef_abs / np.sum(coef_abs)\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = en.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('Elastic_Net_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "gmBntZfWoG6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oexaUi8YWCzY",
        "outputId": "e2fa7d55-5f0c-4740-e486-7f770081d8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap) (1.0.2)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap) (23.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap) (6.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap) (3.15.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data_subset.csv')"
      ],
      "metadata": {
        "id": "ReLwqioZVopZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into input features and target variable\n",
        "X = data.iloc[:, 1:-1] # all columns except the last and first one\n",
        "y = data.iloc[:,-1] # the last column as the target variable\n"
      ],
      "metadata": {
        "id": "OXGqUuWUVr8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UtErkfvL3X3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_regression, k=10) # select top 10 features\n",
        "X_selected = selector.fit_transform(X, y)"
      ],
      "metadata": {
        "id": "IgpXIjZQ3ZYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "oYDu57qX3dvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_selected, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG5jktR43g1H",
        "outputId": "07909751-b886-48cb-b695-ade0421a5263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf.feature_importances_"
      ],
      "metadata": {
        "id": "yMd3i2wi3oX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_selected)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)"
      ],
      "metadata": {
        "id": "3ZE1jTp13p3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=False)"
      ],
      "metadata": {
        "id": "WPSNwyd-3up2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a random forest regressor model with Gini impurity\n",
        "rf = RandomForestRegressor(n_estimators=100, criterion='friedman_mse', max_features='auto', random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlehPxqlW_9Y",
        "outputId": "dc278dbd-740a-4db8-dde3-827236f62aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 1: 0.000\n",
            "Feature 2: 0.006\n",
            "Feature 3: 0.000\n",
            "Feature 4: 0.041\n",
            "Feature 5: 0.001\n",
            "Feature 6: 0.001\n",
            "Feature 7: 0.002\n",
            "Feature 8: 0.003\n",
            "Feature 9: 0.000\n",
            "Feature 10: 0.001\n",
            "Feature 11: 0.005\n",
            "Feature 12: 0.008\n",
            "Feature 13: 0.007\n",
            "Feature 14: 0.008\n",
            "Feature 15: 0.000\n",
            "Feature 16: 0.002\n",
            "Feature 17: 0.004\n",
            "Feature 18: 0.002\n",
            "Feature 19: 0.000\n",
            "Feature 20: 0.007\n",
            "Feature 21: 0.003\n",
            "Feature 22: 0.000\n",
            "Feature 23: 0.013\n",
            "Feature 24: 0.008\n",
            "Feature 25: 0.003\n",
            "Feature 26: 0.001\n",
            "Feature 27: 0.000\n",
            "Feature 28: 0.003\n",
            "Feature 29: 0.001\n",
            "Feature 30: 0.003\n",
            "Feature 31: 0.002\n",
            "Feature 32: 0.000\n",
            "Feature 33: 0.015\n",
            "Feature 34: 0.003\n",
            "Feature 35: 0.003\n",
            "Feature 36: 0.001\n",
            "Feature 37: 0.003\n",
            "Feature 38: 0.001\n",
            "Feature 39: 0.004\n",
            "Feature 40: 0.001\n",
            "Feature 41: 0.000\n",
            "Feature 42: 0.007\n",
            "Feature 43: 0.001\n",
            "Feature 44: 0.001\n",
            "Feature 45: 0.007\n",
            "Feature 46: 0.005\n",
            "Feature 47: 0.004\n",
            "Feature 48: 0.000\n",
            "Feature 49: 0.001\n",
            "Feature 50: 0.003\n",
            "Feature 51: 0.002\n",
            "Feature 52: 0.096\n",
            "Feature 53: 0.001\n",
            "Feature 54: 0.000\n",
            "Feature 55: 0.006\n",
            "Feature 56: 0.000\n",
            "Feature 57: 0.001\n",
            "Feature 58: 0.000\n",
            "Feature 59: 0.007\n",
            "Feature 60: 0.001\n",
            "Feature 61: 0.001\n",
            "Feature 62: 0.005\n",
            "Feature 63: 0.014\n",
            "Feature 64: 0.007\n",
            "Feature 65: 0.000\n",
            "Feature 66: 0.004\n",
            "Feature 67: 0.001\n",
            "Feature 68: 0.001\n",
            "Feature 69: 0.001\n",
            "Feature 70: 0.002\n",
            "Feature 71: 0.006\n",
            "Feature 72: 0.090\n",
            "Feature 73: 0.001\n",
            "Feature 74: 0.005\n",
            "Feature 75: 0.001\n",
            "Feature 76: 0.000\n",
            "Feature 77: 0.002\n",
            "Feature 78: 0.001\n",
            "Feature 79: 0.002\n",
            "Feature 80: 0.001\n",
            "Feature 81: 0.006\n",
            "Feature 82: 0.003\n",
            "Feature 83: 0.002\n",
            "Feature 84: 0.000\n",
            "Feature 85: 0.003\n",
            "Feature 86: 0.002\n",
            "Feature 87: 0.002\n",
            "Feature 88: 0.001\n",
            "Feature 89: 0.007\n",
            "Feature 90: 0.010\n",
            "Feature 91: 0.005\n",
            "Feature 92: 0.007\n",
            "Feature 93: 0.011\n",
            "Feature 94: 0.007\n",
            "Feature 95: 0.001\n",
            "Feature 96: 0.003\n",
            "Feature 97: 0.007\n",
            "Feature 98: 0.004\n",
            "Feature 99: 0.004\n",
            "Feature 100: 0.000\n",
            "Feature 101: 0.017\n",
            "Feature 102: 0.001\n",
            "Feature 103: 0.006\n",
            "Feature 104: 0.001\n",
            "Feature 105: 0.001\n",
            "Feature 106: 0.002\n",
            "Feature 107: 0.010\n",
            "Feature 108: 0.005\n",
            "Feature 109: 0.005\n",
            "Feature 110: 0.001\n",
            "Feature 111: 0.001\n",
            "Feature 112: 0.001\n",
            "Feature 113: 0.002\n",
            "Feature 114: 0.001\n",
            "Feature 115: 0.006\n",
            "Feature 116: 0.006\n",
            "Feature 117: 0.006\n",
            "Feature 118: 0.002\n",
            "Feature 119: 0.002\n",
            "Feature 120: 0.002\n",
            "Feature 121: 0.002\n",
            "Feature 122: 0.004\n",
            "Feature 123: 0.002\n",
            "Feature 124: 0.006\n",
            "Feature 125: 0.007\n",
            "Feature 126: 0.000\n",
            "Feature 127: 0.007\n",
            "Feature 128: 0.000\n",
            "Feature 129: 0.000\n",
            "Feature 130: 0.000\n",
            "Feature 131: 0.001\n",
            "Feature 132: 0.001\n",
            "Feature 133: 0.018\n",
            "Feature 134: 0.043\n",
            "Feature 135: 0.000\n",
            "Feature 136: 0.007\n",
            "Feature 137: 0.013\n",
            "Feature 138: 0.002\n",
            "Feature 139: 0.000\n",
            "Feature 140: 0.001\n",
            "Feature 141: 0.000\n",
            "Feature 142: 0.003\n",
            "Feature 143: 0.001\n",
            "Feature 144: 0.031\n",
            "Feature 145: 0.019\n",
            "Feature 146: 0.009\n",
            "Feature 147: 0.002\n",
            "Feature 148: 0.000\n",
            "Feature 149: 0.002\n",
            "Feature 150: 0.002\n",
            "Feature 151: 0.001\n",
            "Feature 152: 0.012\n",
            "Feature 153: 0.000\n",
            "Feature 154: 0.000\n",
            "Feature 155: 0.015\n",
            "Feature 156: 0.002\n",
            "Feature 157: 0.002\n",
            "Feature 158: 0.005\n",
            "Feature 159: 0.013\n",
            "Feature 160: 0.008\n",
            "Feature 161: 0.003\n",
            "Feature 162: 0.001\n",
            "Feature 163: 0.030\n",
            "Feature 164: 0.001\n",
            "Feature 165: 0.000\n",
            "Feature 166: 0.006\n",
            "Feature 167: 0.001\n",
            "Feature 168: 0.004\n",
            "Feature 169: 0.002\n",
            "Feature 170: 0.004\n",
            "Feature 171: 0.001\n",
            "Feature 172: 0.000\n",
            "Feature 173: 0.001\n",
            "Feature 174: 0.006\n",
            "Feature 175: 0.004\n",
            "Feature 176: 0.000\n",
            "Feature 177: 0.003\n",
            "Feature 178: 0.000\n",
            "Feature 179: 0.002\n",
            "Feature 180: 0.001\n",
            "Feature 181: 0.027\n",
            "Feature 182: 0.005\n",
            "Feature 183: 0.001\n",
            "Feature 184: 0.003\n",
            "Feature 185: 0.001\n",
            "Feature 186: 0.000\n",
            "Feature 187: 0.000\n",
            "Feature 188: 0.005\n",
            "Feature 189: 0.017\n",
            "Feature 190: 0.008\n",
            "Feature 191: 0.003\n"
          ]
        }
      ]
    }
  ]
}