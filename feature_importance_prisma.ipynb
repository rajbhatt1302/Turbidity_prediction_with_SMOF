{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Iajx735-L7O"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('/content/Data_subset1.csv')"
      ],
      "metadata": {
        "id": "a5xUFQFY-kw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "OeXrg_tq-rKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target (y)\n",
        "X = data.iloc[:, 1:192].values\n",
        "y = data.iloc[:, 192].values"
      ],
      "metadata": {
        "id": "w6Hlh5Mu-vIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "nvo-VaJqBhXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of regressors to use\n",
        "regressors = [RandomForestRegressor(n_estimators=100, random_state=0),\n",
        "              DecisionTreeRegressor(random_state=0),\n",
        "              LinearRegression(),\n",
        "              Ridge(),\n",
        "              Lasso(),\n",
        "              SVR(),\n",
        "              KNeighborsRegressor(),\n",
        "              XGBRegressor(random_state=0),\n",
        "              LGBMRegressor(random_state=0)]"
      ],
      "metadata": {
        "id": "oelCX7_HBoLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each regressor\n",
        "for regressor in regressors:\n",
        "    # Train the regressor\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the target values\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    # Calculate the mean squared error and R-squared score\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print the results\n",
        "    print(regressor.__class__.__name__)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAPE:', mape)\n",
        "    print('R-squared:', r2)\n",
        "    #print('Feature Importances:', regressor.feature_importances_ if hasattr(regressor, 'feature_importances_') else 'N/A')\n",
        "    print('-' * 50)\n",
        "\n"
      ],
      "metadata": {
        "id": "zHCS6_y6BsCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('regressor_scores.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Regressor', 'MSE', 'RMSE', 'MAPE', 'R-squared'])\n",
        "    for regressor in regressors:\n",
        "        regressor.fit(X_train, y_train)\n",
        "        y_pred = regressor.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        writer.writerow([regressor.__class__.__name__, mse, rmse, mape, r2])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VS7LWRFQQxp",
        "outputId": "95ffde76-a846-485e-cbc5-5ad67103d48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "id": "5G32nLcmSYAJ",
        "outputId": "ccef163e-a35d-43e4-a44d-566e4d943f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.2.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ],
      "metadata": {
        "id": "prvah1onRu75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Data_subset1.csv')"
      ],
      "metadata": {
        "id": "7oTnzF_uSdUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:192].values\n",
        "y = df.iloc[:, 192].values"
      ],
      "metadata": {
        "id": "_-SQpCQrI9F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YNP-MPE-JJDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the 10 machine learning algorithms\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "lr = LinearRegression()\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "svm = SVR(kernel='linear')\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "lgbm = LGBMRegressor(random_state=42)\n",
        "cat = CatBoostRegressor(random_state=42)\n",
        "mlp = MLPRegressor(random_state=42)\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "et = ExtraTreesRegressor(random_state=42)\n"
      ],
      "metadata": {
        "id": "IpJxrwnbJZCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit each algorithm on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)\n",
        "lgbm.fit(X_train, y_train)\n",
        "cat.fit(X_train, y_train)\n",
        "mlp.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "et.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lTnMag6hJcXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the feature importances for each algorithm\n",
        "rf_feature_importances = rf.feature_importances_\n",
        "lr_feature_importances = lr.coef_\n",
        "dt_feature_importances = dt.feature_importances_\n",
        "svm_feature_importances = None\n",
        "if svm.kernel == 'linear':\n",
        "    svm_feature_importances = svm.coef_\n",
        "else:\n",
        "    svm_feature_importances = svm.feature_importances_\n",
        "xgb_feature_importances = xgb.feature_importances_\n",
        "lgbm_feature_importances = lgbm.feature_importances_\n",
        "cat_feature_importances = cat.feature_importances_\n",
        "mlp_feature_importances = mlp.coefs_\n",
        "gb_feature_importances = gb.feature_importances_\n",
        "et_feature_importances = et.feature_importances_"
      ],
      "metadata": {
        "id": "7SI3wRh2J1Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the feature importances in a dataframe for comparison\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'Algorithm': ['Random Forest', 'Linear Regression', 'Decision Tree', 'Support Vector Machine', 'XGBoost', 'LightGBM', 'CatBoost', 'MLP', 'Gradient Boosting', 'Extra Trees'],\n",
        "    'Feature Importances': [rf_feature_importances, lr_feature_importances, dt_feature_importances, svm_feature_importances, xgb_feature_importances, lgbm_feature_importances,\n",
        "                            cat_feature_importances, mlp_feature_importances, gb_feature_importances, et_feature_importances]\n",
        "})\n",
        "\n",
        "# Save feature importances to a CSV file\n",
        "feature_importances_df.to_csv('feature_importances.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ske4Hn96MJlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ],
      "metadata": {
        "id": "UYIsowTiT89t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:-1]\n",
        "y = data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "WzPb2dMSUCmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "#for i, importance in enumerate(importances):\n",
        "    #print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('RF_feature_importances.csv', index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "KrUvfepIXIyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "svr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.abs(svr.coef_[0])\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = svr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics =\n",
        "\n"
      ],
      "metadata": {
        "id": "xvBMOlbo9xt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)"
      ],
      "metadata": {
        "id": "gJ-R4Ge2YHZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=True)"
      ],
      "metadata": {
        "id": "kQ3VIvM7YIx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = dt.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = dt.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('decision_tree_metrics.csv', index=True)"
      ],
      "metadata": {
        "id": "0cJjPX__fLm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "svr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.abs(svr.coef_[0])\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = svr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('svr_metrics.csv', index=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ynKqVIYb-JSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a XGBRegressor model\n",
        "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "xgb.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = xgb.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('XGB Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = xgb.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('xgb_metrics.csv', index=True)\n"
      ],
      "metadata": {
        "id": "BqS59_p9_VSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LGBMRegressor model\n",
        "lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "lgbm.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = lgbm.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('LGBM Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = lgbm.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('lgbm_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "bhtWBghWWtRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb = CatBoostRegressor(iterations=100, learning_rate=0.1, random_seed=42)\n",
        "cb.fit(X, y, verbose=False)\n",
        "importances = cb.feature_importances_\n",
        "#for i, importance in enumerate(importances):\n",
        " #print('Feature %d: %.3f' % (i+1, importance))\n",
        "# Calculate performance metrics\n",
        "y_pred = cb.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Append feature importances and performance metrics to the CSV file\n",
        "#metrics = metrics.append(pd.DataFrame({'Model': ['XGBRegressor'], 'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}), ignore_index=True)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('catboost_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "8GmxiTW_ZuXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "gbr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = gbr.feature_importances_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = gbr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('gbr_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "k6-Ky_J3lc62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an extra trees regressor model\n",
        "etr = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "etr.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = etr.feature_importances_\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = etr.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('etr_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "erEG5KCGmD0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "metadata": {
        "id": "cvZH2o_knM65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an extra trees regressor model\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = np.zeros(X.shape[1])\n",
        "\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = lgbm.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('knn_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "kxN0H4Nun_YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "zPEYZ3NMqEKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PCA to reduce the number of features\n",
        "pca = PCA(n_components=10)\n",
        "X_pca = pca.fit_transform(X)\n",
        "dt.fit(X_pca, y)\n",
        "importances_pca = dt.feature_importances_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = dt.predict(X_pca)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances_pca, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('pca_dt_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "557z_T98qFOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Create RFE model and select top n features\n",
        "n = 10 # choose the number of top features to select\n",
        "rfe = RFE(estimator=DecisionTreeRegressor(random_state=42), n_features_to_select=n)\n",
        "rfe.fit(X, y)\n",
        "# Get ranking of input features based on RFE\n",
        "rfe_ranking = rfe.ranking_\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rfe.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': rfe_ranking, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('recursive_feature_elimination_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "kkqE6ADvdLV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Calculate permutation importance\n",
        "permutation_importances = permutation_importance(rf, X, y, random_state=42)\n",
        "importances = permutation_importances.importances_mean\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('permutation_importance_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "FlHqaT0KfwiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "sq5ZfWaWoAgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en = ElasticNet(random_state=42)"
      ],
      "metadata": {
        "id": "-o12daXVoDzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en.fit(X, y)\n",
        "importances = np.abs(en.coef_)\n",
        "#importances = coef_abs / np.sum(coef_abs)\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = en.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('Elastic_Net_feature_importance.csv', index=True)"
      ],
      "metadata": {
        "id": "gmBntZfWoG6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oexaUi8YWCzY",
        "outputId": "e2fa7d55-5f0c-4740-e486-7f770081d8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap) (1.0.2)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap) (23.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap) (6.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap) (3.15.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data_subset.csv')"
      ],
      "metadata": {
        "id": "ReLwqioZVopZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into input features and target variable\n",
        "X = data.iloc[:, 1:-1] # all columns except the last and first one\n",
        "y = data.iloc[:,-1] # the last column as the target variable\n"
      ],
      "metadata": {
        "id": "OXGqUuWUVr8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UtErkfvL3X3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(score_func=f_regression, k=10) # select top 10 features\n",
        "X_selected = selector.fit_transform(X, y)"
      ],
      "metadata": {
        "id": "IgpXIjZQ3ZYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "oYDu57qX3dvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_selected, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG5jktR43g1H",
        "outputId": "07909751-b886-48cb-b695-ade0421a5263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf.feature_importances_"
      ],
      "metadata": {
        "id": "yMd3i2wi3oX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_selected)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)"
      ],
      "metadata": {
        "id": "3ZE1jTp13p3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=False)"
      ],
      "metadata": {
        "id": "WPSNwyd-3up2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a random forest regressor model with Gini impurity\n",
        "rf = RandomForestRegressor(n_estimators=100, criterion='friedman_mse', max_features='auto', random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Calculate feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(importances):\n",
        "    print('Feature %d: %.3f' % (i+1, importance))\n",
        "\n",
        "# Calculate performance metrics\n",
        "y_pred = rf.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "# Save feature importances and performance metrics in a CSV file\n",
        "metrics = pd.DataFrame({'Feature Importances': importances, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2})\n",
        "metrics.to_csv('metrics.csv', index=False)\n"
      ],
      "metadata": {
        "id": "FlehPxqlW_9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}