{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjVUUM104CmZ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('SMOF_dataset.csv')\n",
        "X = df[['b21', 'b26', 'b38', 'b48', 'b77']]\n",
        "y = df['Turbidity']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "rf = RandomForestRegressor(n_estimators=120, max_depth=10, random_state=42)\n",
        "# Fit the model to the data\n",
        "rf.fit(X, y)\n",
        "# Make predictions on the data\n",
        "y_pred = rf.predict(X)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "r2 = r2_score(y, y_pred)\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "mape = (abs(y - y_pred) / y).mean() * 100\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MAPE:\", mape)\n",
        "\n",
        "# Add predicted turbidity to the original data\n",
        "data['Turbidity_pred'] = y_pred\n",
        "\n",
        "# Save the updated data to CSV file\n",
        "data.to_csv('BR02TURB_RF.csv', index=False)"
      ],
      "metadata": {
        "id": "MZGbSPKq4LbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('SMOF_dataset.csv')\n",
        "\n",
        "# Handle missing values\n",
        "df.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df[['b21', 'b26', 'b38', 'b48', 'b77']]\n",
        "y = df['Turbidity']\n",
        "\n",
        "# Initialize base models\n",
        "base_models = [\n",
        "    CatBoostRegressor(),\n",
        "    DecisionTreeRegressor(),\n",
        "    ExtraTreesRegressor(),\n",
        "    GradientBoostingRegressor(),\n",
        "    RFE(DecisionTreeRegressor(), n_features_to_select=5),\n",
        "    RandomForestRegressor(),\n",
        "    SVR(),\n",
        "    XGBRegressor(),\n",
        "]\n",
        "\n",
        "# Initialize meta model (Random Forest)\n",
        "meta_model = RandomForestRegressor()\n",
        "\n",
        "# Initialize KFold for 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store meta model predictions\n",
        "meta_model_predictions = []\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Initialize an array to store base model predictions\n",
        "    base_model_predictions = []\n",
        "\n",
        "    # Train and predict using base models\n",
        "    for model in base_models:\n",
        "        model.fit(X_train, y_train)\n",
        "        base_model_predictions.append(model.predict(X_test))\n",
        "\n",
        "    # Stack base model predictions horizontally\n",
        "    stacked_predictions = pd.DataFrame(base_model_predictions).T\n",
        "\n",
        "    # Train meta model on stacked predictions and actual targets\n",
        "    meta_model.fit(stacked_predictions, y_test)\n",
        "\n",
        "    # Use base models to predict on the entire dataset\n",
        "    base_model_predictions_full = []\n",
        "    for model in base_models:\n",
        "        model.fit(X, y)\n",
        "        base_model_predictions_full.append(model.predict(X))\n",
        "\n",
        "    # Stack base model predictions for the entire dataset\n",
        "    stacked_predictions_full = pd.DataFrame(base_model_predictions_full).T\n",
        "\n",
        "    # Use meta model to predict on the stacked predictions\n",
        "    meta_model_prediction = meta_model.predict(stacked_predictions_full)\n",
        "    meta_model_predictions.append(meta_model_prediction)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    rmse_scores.append(mean_squared_error(y, meta_model_prediction, squared=False))\n",
        "    mape_scores.append(mean_absolute_percentage_error(y, meta_model_prediction))\n",
        "    r2_scores.append(r2_score(y, meta_model_prediction))\n",
        "\n",
        "# Calculate average metrics\n",
        "average_rmse = sum(rmse_scores) / len(rmse_scores)\n",
        "average_mape = sum(mape_scores) / len(mape_scores)\n",
        "average_r2 = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "print(\"Average RMSE:\", average_rmse)\n",
        "print(\"Average MAPE:\", average_mape)\n",
        "print(\"Average R2:\", average_r2)\n",
        "\n"
      ],
      "metadata": {
        "id": "eRxbwNMW4tUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}